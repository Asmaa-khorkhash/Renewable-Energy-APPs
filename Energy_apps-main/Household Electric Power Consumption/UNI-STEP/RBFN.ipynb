{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ee92239f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install lightgbm\n",
    "import lightgbm as lgb\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import load_boston\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pandas import DataFrame \n",
    "from Energy_Models.RBFN import RBFN_Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09a8522",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99351d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('household_power_consumption.txt',sep=';', \n",
    "                 parse_dates={'date_time' : ['Date', 'Time']}, infer_datetime_format=True, \n",
    "                 low_memory=False, na_values=['nan','?'], index_col='date_time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9182ec23",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d6a02fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  group data by day\n",
    "data = df.resample('D').sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03c8d7ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Global_active_power</th>\n",
       "      <th>Global_reactive_power</th>\n",
       "      <th>Voltage</th>\n",
       "      <th>Global_intensity</th>\n",
       "      <th>Sub_metering_1</th>\n",
       "      <th>Sub_metering_2</th>\n",
       "      <th>Sub_metering_3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:24:00</th>\n",
       "      <td>4.216</td>\n",
       "      <td>0.418</td>\n",
       "      <td>234.84</td>\n",
       "      <td>18.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:25:00</th>\n",
       "      <td>5.360</td>\n",
       "      <td>0.436</td>\n",
       "      <td>233.63</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:26:00</th>\n",
       "      <td>5.374</td>\n",
       "      <td>0.498</td>\n",
       "      <td>233.29</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:27:00</th>\n",
       "      <td>5.388</td>\n",
       "      <td>0.502</td>\n",
       "      <td>233.74</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:28:00</th>\n",
       "      <td>3.666</td>\n",
       "      <td>0.528</td>\n",
       "      <td>235.68</td>\n",
       "      <td>15.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Global_active_power  Global_reactive_power  Voltage  \\\n",
       "date_time                                                                  \n",
       "2006-12-16 17:24:00                4.216                  0.418   234.84   \n",
       "2006-12-16 17:25:00                5.360                  0.436   233.63   \n",
       "2006-12-16 17:26:00                5.374                  0.498   233.29   \n",
       "2006-12-16 17:27:00                5.388                  0.502   233.74   \n",
       "2006-12-16 17:28:00                3.666                  0.528   235.68   \n",
       "\n",
       "                     Global_intensity  Sub_metering_1  Sub_metering_2  \\\n",
       "date_time                                                               \n",
       "2006-12-16 17:24:00              18.4             0.0             1.0   \n",
       "2006-12-16 17:25:00              23.0             0.0             1.0   \n",
       "2006-12-16 17:26:00              23.0             0.0             2.0   \n",
       "2006-12-16 17:27:00              23.0             0.0             1.0   \n",
       "2006-12-16 17:28:00              15.8             0.0             1.0   \n",
       "\n",
       "                     Sub_metering_3  \n",
       "date_time                            \n",
       "2006-12-16 17:24:00            17.0  \n",
       "2006-12-16 17:25:00            16.0  \n",
       "2006-12-16 17:26:00            17.0  \n",
       "2006-12-16 17:27:00            17.0  \n",
       "2006-12-16 17:28:00            17.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da0c1afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 2075259 entries, 2006-12-16 17:24:00 to 2010-11-26 21:02:00\n",
      "Data columns (total 7 columns):\n",
      " #   Column                 Dtype  \n",
      "---  ------                 -----  \n",
      " 0   Global_active_power    float64\n",
      " 1   Global_reactive_power  float64\n",
      " 2   Voltage                float64\n",
      " 3   Global_intensity       float64\n",
      " 4   Sub_metering_1         float64\n",
      " 5   Sub_metering_2         float64\n",
      " 6   Sub_metering_3         float64\n",
      "dtypes: float64(7)\n",
      "memory usage: 126.7 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36ba8abc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2075259, 7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69661c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling missing values by the value of one day before \n",
    "def fill_missing(data):\n",
    "    one_day = 24*60\n",
    "    for row in range(data.shape[0]):\n",
    "        for col in range(data.shape[1]):\n",
    "            if np.isnan(data[row,col]):\n",
    "                data[row,col] = data[row-one_day,col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6892e81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Global_active_power      0\n",
       "Global_reactive_power    0\n",
       "Voltage                  0\n",
       "Global_intensity         0\n",
       "Sub_metering_1           0\n",
       "Sub_metering_2           0\n",
       "Sub_metering_3           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill_missing(df.values)\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c7f4c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute remaining active power\n",
    "\n",
    "df['sub_metering_remaining'] = (df.Global_active_power * 1000  / 60 ) - (df.Sub_metering_1 + df.Sub_metering_2 + df.Sub_metering_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54ce5e5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Global_active_power</th>\n",
       "      <th>Global_reactive_power</th>\n",
       "      <th>Voltage</th>\n",
       "      <th>Global_intensity</th>\n",
       "      <th>Sub_metering_1</th>\n",
       "      <th>Sub_metering_2</th>\n",
       "      <th>Sub_metering_3</th>\n",
       "      <th>sub_metering_remaining</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-12-16</th>\n",
       "      <td>1209.176</td>\n",
       "      <td>34.922</td>\n",
       "      <td>93552.53</td>\n",
       "      <td>5180.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>546.0</td>\n",
       "      <td>4926.0</td>\n",
       "      <td>14680.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-17</th>\n",
       "      <td>3390.460</td>\n",
       "      <td>226.006</td>\n",
       "      <td>345725.32</td>\n",
       "      <td>14398.6</td>\n",
       "      <td>2033.0</td>\n",
       "      <td>4187.0</td>\n",
       "      <td>13341.0</td>\n",
       "      <td>36946.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-18</th>\n",
       "      <td>2203.826</td>\n",
       "      <td>161.792</td>\n",
       "      <td>347373.64</td>\n",
       "      <td>9247.2</td>\n",
       "      <td>1063.0</td>\n",
       "      <td>2621.0</td>\n",
       "      <td>14018.0</td>\n",
       "      <td>19028.433333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-19</th>\n",
       "      <td>1666.194</td>\n",
       "      <td>150.942</td>\n",
       "      <td>348479.01</td>\n",
       "      <td>7094.0</td>\n",
       "      <td>839.0</td>\n",
       "      <td>7602.0</td>\n",
       "      <td>6197.0</td>\n",
       "      <td>13131.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-20</th>\n",
       "      <td>2225.748</td>\n",
       "      <td>160.998</td>\n",
       "      <td>348923.61</td>\n",
       "      <td>9313.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2648.0</td>\n",
       "      <td>14063.0</td>\n",
       "      <td>20384.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Global_active_power  Global_reactive_power    Voltage  \\\n",
       "date_time                                                           \n",
       "2006-12-16             1209.176                 34.922   93552.53   \n",
       "2006-12-17             3390.460                226.006  345725.32   \n",
       "2006-12-18             2203.826                161.792  347373.64   \n",
       "2006-12-19             1666.194                150.942  348479.01   \n",
       "2006-12-20             2225.748                160.998  348923.61   \n",
       "\n",
       "            Global_intensity  Sub_metering_1  Sub_metering_2  Sub_metering_3  \\\n",
       "date_time                                                                      \n",
       "2006-12-16            5180.8             0.0           546.0          4926.0   \n",
       "2006-12-17           14398.6          2033.0          4187.0         13341.0   \n",
       "2006-12-18            9247.2          1063.0          2621.0         14018.0   \n",
       "2006-12-19            7094.0           839.0          7602.0          6197.0   \n",
       "2006-12-20            9313.0             0.0          2648.0         14063.0   \n",
       "\n",
       "            sub_metering_remaining  \n",
       "date_time                           \n",
       "2006-12-16            14680.933333  \n",
       "2006-12-17            36946.666667  \n",
       "2006-12-18            19028.433333  \n",
       "2006-12-19            13131.900000  \n",
       "2006-12-20            20384.800000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.resample('D').sum()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffa38abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('household_power_consumption.csv')\n",
    "#index >> date-time\n",
    "df = pd.read_csv('household_power_consumption.csv',parse_dates=['date_time'], index_col= 'date_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25853745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Global_active_power</th>\n",
       "      <th>Global_reactive_power</th>\n",
       "      <th>Voltage</th>\n",
       "      <th>Global_intensity</th>\n",
       "      <th>Sub_metering_1</th>\n",
       "      <th>Sub_metering_2</th>\n",
       "      <th>Sub_metering_3</th>\n",
       "      <th>sub_metering_remaining</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-12-16</th>\n",
       "      <td>1209.176</td>\n",
       "      <td>34.922</td>\n",
       "      <td>93552.53</td>\n",
       "      <td>5180.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>546.0</td>\n",
       "      <td>4926.0</td>\n",
       "      <td>14680.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-17</th>\n",
       "      <td>3390.460</td>\n",
       "      <td>226.006</td>\n",
       "      <td>345725.32</td>\n",
       "      <td>14398.6</td>\n",
       "      <td>2033.0</td>\n",
       "      <td>4187.0</td>\n",
       "      <td>13341.0</td>\n",
       "      <td>36946.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-18</th>\n",
       "      <td>2203.826</td>\n",
       "      <td>161.792</td>\n",
       "      <td>347373.64</td>\n",
       "      <td>9247.2</td>\n",
       "      <td>1063.0</td>\n",
       "      <td>2621.0</td>\n",
       "      <td>14018.0</td>\n",
       "      <td>19028.433333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-19</th>\n",
       "      <td>1666.194</td>\n",
       "      <td>150.942</td>\n",
       "      <td>348479.01</td>\n",
       "      <td>7094.0</td>\n",
       "      <td>839.0</td>\n",
       "      <td>7602.0</td>\n",
       "      <td>6197.0</td>\n",
       "      <td>13131.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-20</th>\n",
       "      <td>2225.748</td>\n",
       "      <td>160.998</td>\n",
       "      <td>348923.61</td>\n",
       "      <td>9313.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2648.0</td>\n",
       "      <td>14063.0</td>\n",
       "      <td>20384.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-22</th>\n",
       "      <td>2041.536</td>\n",
       "      <td>142.354</td>\n",
       "      <td>345883.85</td>\n",
       "      <td>8660.4</td>\n",
       "      <td>4855.0</td>\n",
       "      <td>2110.0</td>\n",
       "      <td>10136.0</td>\n",
       "      <td>16924.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-23</th>\n",
       "      <td>1577.536</td>\n",
       "      <td>137.450</td>\n",
       "      <td>346428.76</td>\n",
       "      <td>6731.2</td>\n",
       "      <td>1871.0</td>\n",
       "      <td>458.0</td>\n",
       "      <td>7611.0</td>\n",
       "      <td>16352.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-24</th>\n",
       "      <td>1796.248</td>\n",
       "      <td>132.460</td>\n",
       "      <td>345644.59</td>\n",
       "      <td>7559.4</td>\n",
       "      <td>1096.0</td>\n",
       "      <td>2848.0</td>\n",
       "      <td>12224.0</td>\n",
       "      <td>13769.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-25</th>\n",
       "      <td>1431.164</td>\n",
       "      <td>116.128</td>\n",
       "      <td>347812.21</td>\n",
       "      <td>6004.0</td>\n",
       "      <td>1076.0</td>\n",
       "      <td>426.0</td>\n",
       "      <td>5072.0</td>\n",
       "      <td>17278.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-11-26</th>\n",
       "      <td>1488.104</td>\n",
       "      <td>120.826</td>\n",
       "      <td>303487.57</td>\n",
       "      <td>6259.8</td>\n",
       "      <td>1080.0</td>\n",
       "      <td>385.0</td>\n",
       "      <td>9989.0</td>\n",
       "      <td>13347.733333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1442 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Global_active_power  Global_reactive_power    Voltage  \\\n",
       "date_time                                                           \n",
       "2006-12-16             1209.176                 34.922   93552.53   \n",
       "2006-12-17             3390.460                226.006  345725.32   \n",
       "2006-12-18             2203.826                161.792  347373.64   \n",
       "2006-12-19             1666.194                150.942  348479.01   \n",
       "2006-12-20             2225.748                160.998  348923.61   \n",
       "...                         ...                    ...        ...   \n",
       "2010-11-22             2041.536                142.354  345883.85   \n",
       "2010-11-23             1577.536                137.450  346428.76   \n",
       "2010-11-24             1796.248                132.460  345644.59   \n",
       "2010-11-25             1431.164                116.128  347812.21   \n",
       "2010-11-26             1488.104                120.826  303487.57   \n",
       "\n",
       "            Global_intensity  Sub_metering_1  Sub_metering_2  Sub_metering_3  \\\n",
       "date_time                                                                      \n",
       "2006-12-16            5180.8             0.0           546.0          4926.0   \n",
       "2006-12-17           14398.6          2033.0          4187.0         13341.0   \n",
       "2006-12-18            9247.2          1063.0          2621.0         14018.0   \n",
       "2006-12-19            7094.0           839.0          7602.0          6197.0   \n",
       "2006-12-20            9313.0             0.0          2648.0         14063.0   \n",
       "...                      ...             ...             ...             ...   \n",
       "2010-11-22            8660.4          4855.0          2110.0         10136.0   \n",
       "2010-11-23            6731.2          1871.0           458.0          7611.0   \n",
       "2010-11-24            7559.4          1096.0          2848.0         12224.0   \n",
       "2010-11-25            6004.0          1076.0           426.0          5072.0   \n",
       "2010-11-26            6259.8          1080.0           385.0          9989.0   \n",
       "\n",
       "            sub_metering_remaining  \n",
       "date_time                           \n",
       "2006-12-16            14680.933333  \n",
       "2006-12-17            36946.666667  \n",
       "2006-12-18            19028.433333  \n",
       "2006-12-19            13131.900000  \n",
       "2006-12-20            20384.800000  \n",
       "...                            ...  \n",
       "2010-11-22            16924.600000  \n",
       "2010-11-23            16352.266667  \n",
       "2010-11-24            13769.466667  \n",
       "2010-11-25            17278.733333  \n",
       "2010-11-26            13347.733333  \n",
       "\n",
       "[1442 rows x 8 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7eeb2bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1442, 8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.resample('D').mean()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4dac4873",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df):\n",
    "    \n",
    "    # compute split point\n",
    "    end_idx = df.shape[0]* 70 // 100\n",
    "    \n",
    "    train_data = df.iloc[:end_idx, : ]\n",
    "    test_data = df.iloc[end_idx:, :]\n",
    "    \n",
    "    return train_data, test_data\n",
    "\n",
    "# Split the data into train and test\n",
    "X_train, X_test = train_test_split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2552e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((433, 8), (1009, 8))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape , X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51fa7977",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(train, test):\n",
    "    scaler = MinMaxScaler().fit(train)\n",
    "    return scaler.transform(train), scaler.transform(test), scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "feeee524",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, scaler = scale_data(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db509976",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_supervised(df):\n",
    "\n",
    "    input_features = []\n",
    "    ouput_feature = []\n",
    "    \n",
    "    len_df = df.shape[0]\n",
    "    for i in range(len_df):\n",
    "        \n",
    "        end_idx = i + 1 \n",
    "        \n",
    "        if end_idx > len_df-1:\n",
    "            break\n",
    "            \n",
    "        input_x , output_y = df[i:end_idx, 1:], df[end_idx: end_idx+1, 0]\n",
    "        input_features.append(input_x)\n",
    "        ouput_feature.append(output_y)\n",
    "    \n",
    "    return np.array(input_features), np.mean(np.array(ouput_feature), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea1b9060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of (training data) input features : (1008, 1, 7) and ouput feature (1008,)\n"
     ]
    }
   ],
   "source": [
    "# Split the training data into input features and out feature\n",
    "X_train, Y_train = convert_to_supervised(X_train)\n",
    "print('Shape of (training data) input features : %s and ouput feature %s' % (X_train.shape, Y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e64765e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of (testing data) input features : (432, 1, 7) and ouput feature (432,)\n"
     ]
    }
   ],
   "source": [
    "# Split the testing data into input features and out feature\n",
    "X_test, Y_test = convert_to_supervised(X_test)\n",
    "print('Shape of (testing data) input features : %s and ouput feature %s' % (X_test.shape, Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21faae3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.        , 0.        , 0.21100628, ..., 0.04509043,\n",
       "         0.19965973, 0.20812382]],\n",
       "\n",
       "       [[0.4990285 , 0.96712049, 0.69522599, ..., 0.34577587,\n",
       "         0.66148949, 0.58282399]],\n",
       "\n",
       "       [[0.33132939, 0.97344205, 0.4246181 , ..., 0.21645057,\n",
       "         0.69864442, 0.28128597]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.42522564, 0.96791721, 0.32840243, ..., 0.28656371,\n",
       "         0.6638494 , 0.14893385]],\n",
       "\n",
       "       [[0.34566689, 0.97415423, 0.21199386, ..., 0.04649434,\n",
       "         0.46221393, 0.1313267 ]],\n",
       "\n",
       "       [[0.35070721, 0.97271034, 0.24435292, ..., 0.05384425,\n",
       "         0.43153504, 0.14793817]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d9ee306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6942518 , 0.43190139, 0.31303746, ..., 0.21514682, 0.24844398,\n",
       "       0.41684177])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb67e70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_squared_log_error, mean_absolute_percentage_error\n",
    "def root_mean_squared_error(y_true, y_pred):    \n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d8173156",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps, n_features = X_train.shape[1], X_train.shape[2]\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10)\n",
    "RBFN_Model = RBFN_Model(n_steps,n_features).getModel() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bcf13f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1, 7)]            0         \n",
      "                                                                 \n",
      " build_model_1 (BuildModel)  (None, 1)                 4638      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,638\n",
      "Trainable params: 4,624\n",
      "Non-trainable params: 14\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "RBFN_Model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "51acfde4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "3/3 [==============================] - 3s 385ms/step - loss: 0.0812 - val_loss: 0.1126\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.0804 - val_loss: 0.1116\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.0793 - val_loss: 0.1105\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0787 - val_loss: 0.1095\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0771 - val_loss: 0.1084\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.0762 - val_loss: 0.1073\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.0751 - val_loss: 0.1062\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0739 - val_loss: 0.1050\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0733 - val_loss: 0.1039\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0727 - val_loss: 0.1027\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0716 - val_loss: 0.1015\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0705 - val_loss: 0.1004\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.0695 - val_loss: 0.0992\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.0690 - val_loss: 0.0980\n",
      "Epoch 15/200\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.0680 - val_loss: 0.0968\n",
      "Epoch 16/200\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0674 - val_loss: 0.0956\n",
      "Epoch 17/200\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0668 - val_loss: 0.0945\n",
      "Epoch 18/200\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0656 - val_loss: 0.0933\n",
      "Epoch 19/200\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0654 - val_loss: 0.0922\n",
      "Epoch 20/200\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.0649 - val_loss: 0.0910\n",
      "Epoch 21/200\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0641 - val_loss: 0.0899\n",
      "Epoch 22/200\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0634 - val_loss: 0.0888\n",
      "Epoch 23/200\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0630 - val_loss: 0.0877\n",
      "Epoch 24/200\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0624 - val_loss: 0.0867\n",
      "Epoch 25/200\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.0620 - val_loss: 0.0856\n",
      "Epoch 26/200\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0614 - val_loss: 0.0846\n",
      "Epoch 27/200\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0610 - val_loss: 0.0836\n",
      "Epoch 28/200\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0606 - val_loss: 0.0826\n",
      "Epoch 29/200\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.0602 - val_loss: 0.0816\n",
      "Epoch 30/200\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.0596 - val_loss: 0.0807\n",
      "Epoch 31/200\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0594 - val_loss: 0.0798\n",
      "Epoch 32/200\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0589 - val_loss: 0.0789\n",
      "Epoch 33/200\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0585 - val_loss: 0.0780\n",
      "Epoch 34/200\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.0581 - val_loss: 0.0771\n",
      "Epoch 35/200\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.0578 - val_loss: 0.0763\n",
      "Epoch 36/200\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.0573 - val_loss: 0.0755\n",
      "Epoch 37/200\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0571 - val_loss: 0.0747\n",
      "Epoch 38/200\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.0567 - val_loss: 0.0739\n",
      "Epoch 39/200\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 0.0564 - val_loss: 0.0731\n",
      "Epoch 40/200\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.0561 - val_loss: 0.0723\n",
      "Epoch 41/200\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.0558 - val_loss: 0.0716\n",
      "Epoch 42/200\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.0554 - val_loss: 0.0708\n",
      "Epoch 43/200\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.0551 - val_loss: 0.0701\n",
      "Epoch 44/200\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.0549 - val_loss: 0.0694\n",
      "Epoch 45/200\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0546 - val_loss: 0.0687\n",
      "Epoch 46/200\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0543 - val_loss: 0.0680\n",
      "Epoch 47/200\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0539 - val_loss: 0.0674\n",
      "Epoch 48/200\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0538 - val_loss: 0.0667\n",
      "Epoch 49/200\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.0534 - val_loss: 0.0660\n",
      "Epoch 50/200\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0531 - val_loss: 0.0654\n",
      "Epoch 51/200\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0528 - val_loss: 0.0648\n",
      "Epoch 52/200\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0525 - val_loss: 0.0641\n",
      "Epoch 53/200\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.0524 - val_loss: 0.0635\n",
      "Epoch 54/200\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0521 - val_loss: 0.0629\n",
      "Epoch 55/200\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0518 - val_loss: 0.0623\n",
      "Epoch 56/200\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.0516 - val_loss: 0.0617\n",
      "Epoch 57/200\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0512 - val_loss: 0.0611\n",
      "Epoch 58/200\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0510 - val_loss: 0.0605\n",
      "Epoch 59/200\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0508 - val_loss: 0.0599\n",
      "Epoch 60/200\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0505 - val_loss: 0.0593\n",
      "Epoch 61/200\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0503 - val_loss: 0.0587\n",
      "Epoch 62/200\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0502 - val_loss: 0.0581\n",
      "Epoch 63/200\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0499 - val_loss: 0.0575\n",
      "Epoch 64/200\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.0496 - val_loss: 0.0570\n",
      "Epoch 65/200\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0494 - val_loss: 0.0564\n",
      "Epoch 66/200\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0492 - val_loss: 0.0558\n",
      "Epoch 67/200\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0489 - val_loss: 0.0552\n",
      "Epoch 68/200\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0487 - val_loss: 0.0546\n",
      "Epoch 69/200\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.0485 - val_loss: 0.0541\n",
      "Epoch 70/200\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0483 - val_loss: 0.0535\n",
      "Epoch 71/200\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0480 - val_loss: 0.0530\n",
      "Epoch 72/200\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.0478 - val_loss: 0.0525\n",
      "Epoch 73/200\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0476 - val_loss: 0.0519\n",
      "Epoch 74/200\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0474 - val_loss: 0.0514\n",
      "Epoch 75/200\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0472 - val_loss: 0.0509\n",
      "Epoch 76/200\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0470 - val_loss: 0.0505\n",
      "Epoch 77/200\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0468 - val_loss: 0.0500\n",
      "Epoch 78/200\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0466 - val_loss: 0.0495\n",
      "Epoch 79/200\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.0464 - val_loss: 0.0490\n",
      "Epoch 80/200\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.0462 - val_loss: 0.0486\n",
      "Epoch 81/200\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0460 - val_loss: 0.0481\n",
      "Epoch 82/200\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.0458 - val_loss: 0.0477\n",
      "Epoch 83/200\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0456 - val_loss: 0.0472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/200\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0454 - val_loss: 0.0468\n",
      "Epoch 85/200\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0452 - val_loss: 0.0464\n",
      "Epoch 86/200\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0450 - val_loss: 0.0460\n",
      "Epoch 87/200\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0448 - val_loss: 0.0456\n",
      "Epoch 88/200\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.0446 - val_loss: 0.0452\n",
      "Epoch 89/200\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0445 - val_loss: 0.0448\n",
      "Epoch 90/200\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0443 - val_loss: 0.0444\n",
      "Epoch 91/200\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0441 - val_loss: 0.0441\n",
      "Epoch 92/200\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0439 - val_loss: 0.0437\n",
      "Epoch 93/200\n",
      "3/3 [==============================] - 0s 200ms/step - loss: 0.0437 - val_loss: 0.0433\n",
      "Epoch 94/200\n",
      "3/3 [==============================] - 1s 361ms/step - loss: 0.0435 - val_loss: 0.0430\n",
      "Epoch 95/200\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.0433 - val_loss: 0.0427\n",
      "Epoch 96/200\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.0432 - val_loss: 0.0423\n",
      "Epoch 97/200\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0430 - val_loss: 0.0420\n",
      "Epoch 98/200\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0428 - val_loss: 0.0417\n",
      "Epoch 99/200\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.0427 - val_loss: 0.0413\n",
      "Epoch 100/200\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0425 - val_loss: 0.0410\n",
      "Epoch 101/200\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0423 - val_loss: 0.0407\n",
      "Epoch 102/200\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0421 - val_loss: 0.0404\n",
      "Epoch 103/200\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0420 - val_loss: 0.0401\n",
      "Epoch 104/200\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0418 - val_loss: 0.0398\n",
      "Epoch 105/200\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.0417 - val_loss: 0.0395\n",
      "Epoch 106/200\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0415 - val_loss: 0.0392\n",
      "Epoch 107/200\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.0413 - val_loss: 0.0390\n",
      "Epoch 108/200\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0411 - val_loss: 0.0387\n",
      "Epoch 109/200\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0410 - val_loss: 0.0384\n",
      "Epoch 110/200\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0409 - val_loss: 0.0382\n",
      "Epoch 111/200\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.0407 - val_loss: 0.0379\n",
      "Epoch 112/200\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.0405 - val_loss: 0.0377\n",
      "Epoch 113/200\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0404 - val_loss: 0.0374\n",
      "Epoch 114/200\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0402 - val_loss: 0.0372\n",
      "Epoch 115/200\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0401 - val_loss: 0.0370\n",
      "Epoch 116/200\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0399 - val_loss: 0.0368\n",
      "Epoch 117/200\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0398 - val_loss: 0.0365\n",
      "Epoch 118/200\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.0396 - val_loss: 0.0363\n",
      "Epoch 119/200\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0395 - val_loss: 0.0361\n",
      "Epoch 120/200\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0393 - val_loss: 0.0359\n",
      "Epoch 121/200\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0392 - val_loss: 0.0357\n",
      "Epoch 122/200\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0390 - val_loss: 0.0355\n",
      "Epoch 123/200\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0389 - val_loss: 0.0353\n",
      "Epoch 124/200\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0387 - val_loss: 0.0352\n",
      "Epoch 125/200\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0386 - val_loss: 0.0350\n",
      "Epoch 126/200\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0385 - val_loss: 0.0348\n",
      "Epoch 127/200\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0383 - val_loss: 0.0346\n",
      "Epoch 128/200\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0382 - val_loss: 0.0344\n",
      "Epoch 129/200\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0380 - val_loss: 0.0343\n",
      "Epoch 130/200\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0379 - val_loss: 0.0341\n",
      "Epoch 131/200\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0378 - val_loss: 0.0339\n",
      "Epoch 132/200\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0376 - val_loss: 0.0337\n",
      "Epoch 133/200\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0375 - val_loss: 0.0336\n",
      "Epoch 134/200\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0374 - val_loss: 0.0334\n",
      "Epoch 135/200\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0372 - val_loss: 0.0332\n",
      "Epoch 136/200\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0371 - val_loss: 0.0331\n",
      "Epoch 137/200\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.0370 - val_loss: 0.0329\n",
      "Epoch 138/200\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0368 - val_loss: 0.0328\n",
      "Epoch 139/200\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0367 - val_loss: 0.0326\n",
      "Epoch 140/200\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0366 - val_loss: 0.0324\n",
      "Epoch 141/200\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.0364 - val_loss: 0.0323\n",
      "Epoch 142/200\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0364 - val_loss: 0.0321\n",
      "Epoch 143/200\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0362 - val_loss: 0.0320\n",
      "Epoch 144/200\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.0361 - val_loss: 0.0318\n",
      "Epoch 145/200\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.0360 - val_loss: 0.0317\n",
      "Epoch 146/200\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.0359 - val_loss: 0.0316\n",
      "Epoch 147/200\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.0357 - val_loss: 0.0314\n",
      "Epoch 148/200\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.0356 - val_loss: 0.0313\n",
      "Epoch 149/200\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.0355 - val_loss: 0.0311\n",
      "Epoch 150/200\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0354 - val_loss: 0.0310\n",
      "Epoch 151/200\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0353 - val_loss: 0.0309\n",
      "Epoch 152/200\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0351 - val_loss: 0.0307\n",
      "Epoch 153/200\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.0350 - val_loss: 0.0306\n",
      "Epoch 154/200\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0349 - val_loss: 0.0305\n",
      "Epoch 155/200\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.0348 - val_loss: 0.0303\n",
      "Epoch 156/200\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0347 - val_loss: 0.0302\n",
      "Epoch 157/200\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0346 - val_loss: 0.0301\n",
      "Epoch 158/200\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0345 - val_loss: 0.0300\n",
      "Epoch 159/200\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0343 - val_loss: 0.0298\n",
      "Epoch 160/200\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0342 - val_loss: 0.0297\n",
      "Epoch 161/200\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0341 - val_loss: 0.0296\n",
      "Epoch 162/200\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0340 - val_loss: 0.0295\n",
      "Epoch 163/200\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 0.0339 - val_loss: 0.0293\n",
      "Epoch 164/200\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 0.0338 - val_loss: 0.0292\n",
      "Epoch 165/200\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0337 - val_loss: 0.0291\n",
      "Epoch 166/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0336 - val_loss: 0.0290\n",
      "Epoch 167/200\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0335 - val_loss: 0.0289\n",
      "Epoch 168/200\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0334 - val_loss: 0.0288\n",
      "Epoch 169/200\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0333 - val_loss: 0.0286\n",
      "Epoch 170/200\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0332 - val_loss: 0.0285\n",
      "Epoch 171/200\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0331 - val_loss: 0.0284\n",
      "Epoch 172/200\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.0330 - val_loss: 0.0283\n",
      "Epoch 173/200\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0329 - val_loss: 0.0282\n",
      "Epoch 174/200\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0328 - val_loss: 0.0281\n",
      "Epoch 175/200\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0327 - val_loss: 0.0280\n",
      "Epoch 176/200\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0326 - val_loss: 0.0279\n",
      "Epoch 177/200\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 0.0325 - val_loss: 0.0278\n",
      "Epoch 178/200\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0324 - val_loss: 0.0277\n",
      "Epoch 179/200\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.0323 - val_loss: 0.0276\n",
      "Epoch 180/200\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0322 - val_loss: 0.0275\n",
      "Epoch 181/200\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.0321 - val_loss: 0.0274\n",
      "Epoch 182/200\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0321 - val_loss: 0.0272\n",
      "Epoch 183/200\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0320 - val_loss: 0.0271\n",
      "Epoch 184/200\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0319 - val_loss: 0.0270\n",
      "Epoch 185/200\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.0318 - val_loss: 0.0269\n",
      "Epoch 186/200\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0317 - val_loss: 0.0268\n",
      "Epoch 187/200\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0316 - val_loss: 0.0268\n",
      "Epoch 188/200\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0315 - val_loss: 0.0267\n",
      "Epoch 189/200\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0314 - val_loss: 0.0266\n",
      "Epoch 190/200\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 0.0313 - val_loss: 0.0265\n",
      "Epoch 191/200\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0313 - val_loss: 0.0264\n",
      "Epoch 192/200\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 0.0312 - val_loss: 0.0263\n",
      "Epoch 193/200\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.0311 - val_loss: 0.0262\n",
      "Epoch 194/200\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0310 - val_loss: 0.0261\n",
      "Epoch 195/200\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0309 - val_loss: 0.0260\n",
      "Epoch 196/200\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0309 - val_loss: 0.0259\n",
      "Epoch 197/200\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.0308 - val_loss: 0.0258\n",
      "Epoch 198/200\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.0307 - val_loss: 0.0257\n",
      "Epoch 199/200\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0306 - val_loss: 0.0256\n",
      "Epoch 200/200\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.0305 - val_loss: 0.0256\n"
     ]
    }
   ],
   "source": [
    "RBFN_Model.compile(optimizer='adam', loss ='mse')\n",
    "history = RBFN_Model.fit(X_train , Y_train, epochs=200, batch_size=256, verbose= 1,validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0c2e5d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 4ms/step\n",
      "14/14 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "Y_pred_train = RBFN_Model.predict(X_train)\n",
    "Y_pred_test = RBFN_Model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4db57c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train   RMSE  value for RBFN Model  : 0.170 \n",
      "Train   MSE   value for RBFN Model  : 0.029 \n",
      "Train   R2    value for RBFN Model  : -0.436 \n",
      "Train   MAPE  value for RBFN Model  : 1712373608126.231 \n",
      "Train   RMLSE value for RBFN Model  : 0.018 \n",
      "Train   MAE   value for RBFN Model  : 0.140 \n",
      "---------------------------------------------\n",
      "Test    RMSE  value for RBFN Model  : 0.138 \n",
      "Test    MSE   value for RBFN Model  : 0.019 \n",
      "Test    R2    value for RBFN Model  : -0.723 \n",
      "Test    MAPE  value for RBFN Model  : 0.639 \n",
      "Test    RMLSE value for RBFN Model  : 0.012 \n",
      "Test    MAE   value for RBFN Model  : 0.113 \n"
     ]
    }
   ],
   "source": [
    "print('Train   RMSE  value for RBFN Model  : %.3f ' % root_mean_squared_error(Y_train, Y_pred_train))\n",
    "print('Train   MSE   value for RBFN Model  : %.3f ' % mean_squared_error(Y_train, Y_pred_train))\n",
    "print('Train   R2    value for RBFN Model  : %.3f ' % r2_score(Y_train, Y_pred_train))\n",
    "print('Train   MAPE  value for RBFN Model  : %.3f ' % mean_absolute_percentage_error(Y_train, Y_pred_train))\n",
    "print('Train   RMLSE value for RBFN Model  : %.3f ' % mean_squared_log_error(Y_train, Y_pred_train))\n",
    "print('Train   MAE   value for RBFN Model  : %.3f ' % mean_absolute_error(Y_train, Y_pred_train))\n",
    "print('---------------------------------------------')\n",
    "print('Test    RMSE  value for RBFN Model  : %.3f ' % root_mean_squared_error(Y_test, Y_pred_test))\n",
    "print('Test    MSE   value for RBFN Model  : %.3f ' % mean_squared_error(Y_test, Y_pred_test))\n",
    "print('Test    R2    value for RBFN Model  : %.3f ' % r2_score(Y_test, Y_pred_test))\n",
    "print('Test    MAPE  value for RBFN Model  : %.3f ' % mean_absolute_percentage_error(Y_test, Y_pred_test))\n",
    "print('Test    RMLSE value for RBFN Model  : %.3f ' % mean_squared_log_error(Y_test, Y_pred_test))\n",
    "print('Test    MAE   value for RBFN Model  : %.3f ' % mean_absolute_error(Y_test, Y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "49d3afc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0290\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.029003214091062546"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RBFN_Model.evaluate(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a3729c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0190\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.018953753635287285"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RBFN_Model.evaluate(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "50c5ae11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA6dklEQVR4nO3dd3wVVfr48c+ThBBSSEijJJCE3qUL2FDpqGBDRVjbiuy61e53ddV13VXXddWfa1/XgoKKjRVRRAVERZr0GmoSIJUkJCGknd8fM4FLuAlJyL1zkzzv12teuXfqc8+d3GfmnJkzYoxBKaWUqsrP6QCUUkr5Jk0QSiml3NIEoZRSyi1NEEoppdzSBKGUUsotTRBKKaXc0gThQSKyRER+6aVt/UpE0kWkQESiqkxLFBEjIgHeiKWxquv3VVOZO0VEXhKRB30gjhtFZLnTcbjjzf/Lxk4TxBkSkb0ictT+kUgXkf+KSGgd13FGP+Ai0gJ4GhhrjAk1xmTXZz2q9jxR5va+NPpM1mGMmWWMefRMY/GkhjxgEZE3ROSvDRFXNes/4+/El7ZTV5ogGsalxphQYBAwFHjAy9tvCwQBm7283eas3mUuljr/7+kZoPI2TRANyBiTBiwE+ladJiJ+IvKAiOwTkQwReUtEwu3Jy+y/ufaZyAg3y7cUkWdE5IA9PGOP6w5sd1n+m9PFKSIdRGS+iOSISLKI3OoybZiIrBaRfPuM6Gl7fJCIzBaRbBHJFZFVItLWzbrvE5F5VcY9KyLP2a9vFJHdInJERPaIyPXVxOhnr2uXvc33RSTSnlZ5BDrTLouDInLn6crKZfpkEVlnf8ZdIjLeZdMJIvK9Hd8iEYl2E5vbMheRkXa55Nl/R7oss0REHhOR74EioHOVdb4NdAL+Z+8D97h8zltEZD9QuZ0PROSQvZ1lItLHZT3Hj6hFZJSIpIrInfY+d1BEbnJX3vb8N4nIVvuz7xaR21ym1bguEYmy96l8EVkJdKluO1Szv4vIzfb2D4vIlyKSYI8XEfmXvd08EdkgIn1FZCZwPXCPvZ7/VfO5xojINnvZ5wFxmdZFRL6x97EsEXlHRCKq+05qUf4TRWSLXYZpInKXy7RL7P0uV0R+EJH+NW3HJxhjdDiDAdgLjLZfd8Q6onzUfr8E+KX9+mYgGeuHIRT4CHjbnpYIGCCghu38BVgBxAIxwA8u26lx+arTgaXAC1hHwAOATOBie9qPwAz7dSgw3H59G/A/IBjwBwYDrd1sKwHrB7C1/d4fOAgMB0KAfKCHPa090KeamP9gf954oCXwMjCnyueZY6+zn/0ZRteirIYBecAYrAOkOKCny/e1C+gOtLLfP17LMo0EDgMzgADgOvt9lMu69wN97OktatqXqmzjLftztnLZl8LscnkGWOeyzBvAX+3Xo4AyuzxaABPt76ZNNZ9pEtYPuwAX2PMOqs26gLnA+3acfYE0YHltys4eNwXr/6OXXT4PAD/Y08YBa4AIO7ZeQPuqn7eabUVj7XNX2XH/0f4clf+XXe19oSXWvrIMeKa676QW5X8QOM9+3cal/AYBGcDZWP8TN9jrblnddnxhcDyAxj7YX2wBkAvsw/rhrfxHXuKyI34N/NpluR5Aqf3PcMo/jJvt7AImurwfB+y1X9e4vOt0rCRWDoS5TP878Ib9ehnwCBBdZR03Y/3Q9q9FmSwHfmG/HgPssl+H2OV0ZWUZ1bCOrdhJy37f3k159XSZ/iTwn1qU1cvAv6rZ5hLgAZf3vwa+OF2Z2u9nACurzPMjcKPLuv9Si33JXYLoXMMyEfY84fb7Nzg5QRzl5B/iDOykX4vv8RPg96dbF9YPXmmV7+Nv1C1BLARucXnvh5WAEoCLgB32tvyqrOv4561mW78AVri8FyAV+//SzfxTgJ+r+05qUf77sQ6mWleZ70XsgxSXcduBC2qzHacGrWJqGFOMMRHGmARjzK+NMUfdzNMBK4FU2of1Y3dKNU013C3foR6xdgByjDFHqqwrzn59C9YR9Da7muQSe/zbwJfAXLva5kmxGmrdeRfrCBpgmv0eY0whcA0wCzgoIgtEpGc160gAPrZPx3OxEkY5J5dXSpXPUFkeNZVVR6wEUp1DLq+LsM6iaqPqNiu3G+fyPoX6Ob6ciPiLyON21Vg+1g8LWEfK7mQbY8pc3lf7mURkgoisEKvqMRfrLMF1vdWtKwZrX676fdRFAvCsy/edg/VjHmeM+QZ4Hvg3kC4ir4hI61qut4NrXMb6NXYtz1gRmWtXB+UDs6m+LGtT/ldilds+EVkqJ6qLE4A7Kz+f/Rk7Ur//Ya/RBOE9B7B2kkqdsE5107GOQOqz/IF6xhEpImFV1pUGYIzZaYy5Dqt65glgnoiEGGNKjTGPGGN6AyOBS7COztz5ABglIvHA5dgJwl7/l8aYMVhnBNuAV6tZRwowwU68lUOQsdp5KnWs8hkqy6Omskqh5vrx+qq6zcrtusZ7uu+5uumu46cBk4HRQDjW0Ti41KvXh1htNB8CTwFtjTERwOe1XG8m1r5c9fuojrvPmQLcVuX7bmWM+QHAGPOcMWYwVhVdd+DuGtbl6qBrXCIiVeL8u72O/saY1sB0Tv7MVddfY/kbY1YZYyZj/f98glXtVvn5Hqvy+YKNMXNq+TkcoQnCe+YAfxSRJLEug/0b8J59RJYJVFCl4dLN8g+ISIxYDad/xjraqRNjTApWVdHfxWp47o911vAOgIhMF5EYY0wFVnUQQLmIXCgi/UTEH6tOtxTriN7dNjKxqlT+C+wxxmy1191WRC4TkRDgGFbVnNt1AC8Bj7k0VMaIyOQq8zwoIsF2I+FNwHv2+JrK6j/ATSJysVgN4XE1nMXUxedAdxGZJiIBInIN0Bv4rA7rSKfmfQCsuu9jQDZWe9Df6hOsG4FYdeqZQJmITADG1mZBY0w5Vpvaw/b30Rurjr067vb3l4D7Kxt8RSRcRK62Xw8VkbPtM9ZCoJgT+83pymwB0EdErhDrKrDfAe1cpodhVxGLSBwnEk+lquuvtvxFJFBErheRcGNMKdb/SWWcrwKz7M8hIhIiIpNcDtRq8917n9N1XI19oIa6Q05ug/DD+qFKwfoHmY1LYyFW418m1o/yKXXEWA3Kz2EdER20XwfZ0xKpWyN1PNYPVw5Wdcssl3lnY9UtF2A1uE+xx1+HVWdaiLUzP1fd9uz5Z9jbvNtlXHusBvI8+3MuAXpXs7wfcIe9zSN2nH+r8nlmYh25HwLuqU1Z2dMvBzbY600GxlX9vuz3N1K3evRzsRpT8+y/57rbF2oos8lYddi5wF3VbCMU+NSOfR/WWZwButrT3+DkNojUOuyvt9vfbS5WleLc2q4Lq5rpM6wfxZXAo9WVXXX7u73PbLTXkQK8bo+/2P6+CoAsrIOZUHtaN2CdvZ5PqtnWeKw2jDysqqqlnPi/7GN/VwX2eu50/ZxuvpNqyx8ryX6BdXFCPrCqyj4w3h6Xi7VffoDdFlh1O07/rlUOYgenVKMhIonAHqwrgcpOM7tSqp60ikkppZRbmiCUUkq5pVVMSiml3NIzCKWUUm41qc6/oqOjTWJiotNhKKVUo7FmzZosY0yMu2lNKkEkJiayevVqp8NQSqlGQ0Sqvetdq5iUUkq5pQlCKaWUW5oglFJKudWk2iCUUqquSktLSU1Npbi42OlQPCooKIj4+HhatKiuE+ZTaYJQSjVrqamphIWFkZiYiNXZa9NjjCE7O5vU1FSSkpJqvZxWMSmlmrXi4mKioqKabHIAEBGioqLqfJakCUIp1ew15eRQqT6fURNEeRks/xek6v0TSinlShNE2VFY+Sp8+hsoK3E6GqVUM5Obm8sLL7xQ5+UmTpxIbm5uwwfkQhNEyzC45F+QuRWWP+10NEqpZqa6BFFeXt3DFi2ff/45ERERHorKogkCoPs46Hc1LHsKMrY6HY1Sqhm577772LVrFwMGDGDo0KFceOGFTJs2jX79+gEwZcoUBg8eTJ8+fXjllVeOL5eYmEhWVhZ79+6lV69e3HrrrfTp04exY8dy9OjRBolNL3OtNP5xSP4a5v8Wbv4S/Pydjkgp5WWP/G8zWw7kN+g6e3dozUOX9ql2+uOPP86mTZtYt24dS5YsYdKkSWzatOn45aivv/46kZGRHD16lKFDh3LllVcSFRV10jp27tzJnDlzePXVV5k6dSoffvgh06dPP+PY9QyiUkg0THgCUldZbRJKKeWAYcOGnXSvwnPPPcdZZ53F8OHDSUlJYefOnacsk5SUxIABAwAYPHgwe/fubZBY9AzCVb+rYcP78PVfoOdEiOjkdERKKS+q6UjfW0JCQo6/XrJkCYsXL+bHH38kODiYUaNGub2XoWXLlsdf+/v7N1gVk55BuBKxGqxF4H9/AH3anlLKw8LCwjhy5IjbaXl5ebRp04bg4GC2bdvGihUrvBqbJoiqIjrCxQ/Brq9h04dOR6OUauKioqI455xz6Nu3L3ffffdJ08aPH09ZWRn9+/fnwQcfZPjw4V6NrUk9k3rIkCGmQR4YVFEOr10M+QfgN6sgKPzM16mU8klbt26lV69eTofhFe4+q4isMcYMcTe/nkG44+cPk56Gggz45jGno1FKKUdogqhO3CAY+ktY9SocWOd0NEop5XWaIGpy0QMQHA0L7oCKCqejUUopr9IEUZNWETDuMUhbA2vfcDoapZTyKk0Qp9Pvakg8DxY/AgWZTkejlFJeownidERg0j+hpBAWP+R0NEop5TWaIGojpgeMuB3WvaPPjVBKNaj6dvcN8Mwzz1BUVNTAEZ2gCaK2zr8LQtvBwnu0wVop1WB8OUFoX0y11TIMRj8Mn8yCDXNhwDSnI1JKNQGu3X2PGTOG2NhY3n//fY4dO8bll1/OI488QmFhIVOnTiU1NZXy8nIefPBB0tPTOXDgABdeeCHR0dF8++23DR6bJoi66H8NrHoNFj8MvS61koZSqulYeB8c2tiw62zXDyY8Xu1k1+6+Fy1axLx581i5ciXGGC677DKWLVtGZmYmHTp0YMGCBYDVR1N4eDhPP/003377LdHR0Q0bs02rmOrCzw8mPAkF6bDsH05Ho5RqYhYtWsSiRYsYOHAggwYNYtu2bezcuZN+/fqxePFi7r33Xr777jvCw73T/Y+eQdRV/GAYcD38+AIM/AVEd3U6IqVUQ6nhSN8bjDHcf//93HbbbadMW7NmDZ9//jn3338/Y8eO5c9//rPH49EziPq4+CEICIIv/8/pSJRSjZxrd9/jxo3j9ddfp6CgAIC0tDQyMjI4cOAAwcHBTJ8+nbvuuou1a9eesqwn6BlEfYS1hQvuhq/+DDu/gm5jnI5IKdVIuXb3PWHCBKZNm8aIESMACA0NZfbs2SQnJ3P33Xfj5+dHixYtePHFFwGYOXMmEyZMoH379h5ppNbuvuurrAReGG7dSPerHyEg0DvbVUo1KO3uW7v7bngBgTD+75CdDCtfdjoapZRqcJogzkT3cdB1DCx9UvtpUko1OR5NECIyXkS2i0iyiNznZnpPEflRRI6JyF11WdZnjP87lBbBN486HYlSqp6aUlV7derzGT2WIETEH/g3MAHoDVwnIr2rzJYD/A54qh7L+obobjBsJqx9Cw5ucDoapVQdBQUFkZ2d3aSThDGG7OxsgoKC6rScJ69iGgYkG2N2A4jIXGAysKVyBmNMBpAhIpPquqxPueAeWD8XvrgfbvzMarhWSjUK8fHxpKamkpnZtKuJg4KCiI+Pr9MynkwQcUCKy/tU4OyGXlZEZgIzATp16lT3KBtCqzZw0Z9gwZ2wdT70nuxMHEqpOmvRogVJSUlOh+GTPNkG4e4wurbncLVe1hjzijFmiDFmSExMTK2Da3CDboTY3rDoASgtdi4OpZRqIJ5MEKlAR5f38cABLyzrDP8Aq8E6dz/8+LzT0Sil1BnzZIJYBXQTkSQRCQSuBeZ7YVnndB4FPS+B756G/INOR6OUUmfEYwnCGFMG/Ab4EtgKvG+M2Swis0RkFoCItBORVOAO4AERSRWR1tUt66lYG9TYR6GiFL7+i9ORKKXUGdGuNjzhqz/D98/Crd9A3GCno1FKqWppVxvedt5dEBJrXfbahBKwUqp50QThCUGt4eIHIeUn2PSh09EopVS9aILwlAHXQ7v+VnVTieceKq6UUp6iCcJT/PxhwhOQnwY/POd0NEopVWeaIDwpYST0ngLLn4G8VKejUUqpOtEE4Wlj/gIY+OohpyNRSqk60QThaW0SYORvYdM82P+T09EopVStaYLwhnP+AGHt4Yt7oaLC6WiUUqpWNEF4Q8tQGP0wHPgZNsx1OhqllKoVTRDe0m+qdVf14kfgWIHT0Sil1GlpgvAWPz8Y/wQUHILlTzsdjVJKnZYmCG/qONQ6k/jhecjZ7XQ0SilVI00Q3jbmEfBvYfXTpJRSPkwThLe17gAX3As7voDtC52ORimlqqUJwgnDfwUxPWHhvVB61OlolFLKLU0QTvBvARP/Abn7rG44lFLKB2mCcErS+dD3Slj+L8jZ43Q0Sil1Ck0QThr7V7vB+j6nI1FKqVNognCSNlgrpXyYJginVTZYf36P3mGtlPIpmiCc5t8CLnkG8vbDkr87HY1SSh2nCcIXJIyAwTfBihesDv2UUsoHaILwFaMfhpAYmP87KC9zOhqllNIE4TNaRcCEJ+HQBvjpRaejUUopTRA+pfdk6D4Bvv0bHN7rdDRKqWZOE4QvEYFJT4H4wYI7wRinI1JKNWOaIHxNeDxc9CAkL4YN7zkdjVKqGdME4YuG3Qodz4aF90D+QaejUUo1U5ogfJGfP0x+AcpK4H+/16ompZQjNEH4quiuMPoh2PklrJ/jdDRKqWZIE4QvG3YbdBoJC++DvDSno1FKNTOaIHyZnx9M+TdUlML/fqdVTUopr9IE4esiO8PoR6yrmn5+2+lolFLNiCaIxmDoLyHxPPjifsjZ7XQ0SqlmQhNEY+DnB1NetK5u+vCXUF7qdERKqWZAEwSQnHGE4tJyp8OoWURHuPQ5SFuj3YIrpbzCowlCRMaLyHYRSRaRU56rKZbn7OkbRGSQy7Q/ishmEdkkInNEJMgTMR4uLOGKF37g93N/przCxxuB+0yBQb+A756GPcucjkYp1cR5LEGIiD/wb2AC0Bu4TkR6V5ltAtDNHmYCL9rLxgG/A4YYY/oC/sC1noizTUggvx/dnS83p/PoZ1s8sYmGNf5xiOoCH90GRTlOR6OUasI8eQYxDEg2xuw2xpQAc4HJVeaZDLxlLCuACBFpb08LAFqJSAAQDBzwVKC3nJvETeck8sYPe/l2W4anNtMwAkPgyv9AYSbM/61e+qqU8hhPJog4IMXlfao97rTzGGPSgKeA/cBBIM8Ys8jdRkRkpoisFpHVmZmZ9Q72/gm96BwTwkPzN/t+e0SHAdZd1ts+g1WvOR2NUqqJ8mSCEDfjqh7uup1HRNpgnV0kAR2AEBGZ7m4jxphXjDFDjDFDYmJi6h1sYIAfj07uy/6cIh5bsBXj60fmw2+HrmPgy/+DtLVOR6OUaoI8mSBSgY4u7+M5tZqounlGA3uMMZnGmFLgI2CkB2MF4Jyu0dxybhJvr9jH/328ybeThJ8fXPEKhLaF92/Q9gilVIPzZIJYBXQTkSQRCcRqZJ5fZZ75wC/sq5mGY1UlHcSqWhouIsEiIsDFwFYPxnrcA5N6cdv5nZmzcj9Ld9S/ysorgiPh6jfhyEH45FdQUeF0REqpJsRjCcIYUwb8BvgS68f9fWPMZhGZJSKz7Nk+B3YDycCrwK/tZX8C5gFrgY12nK94KlZXIsKdY3sQE9aS/36/1xubPDPxg2Hc32DHF/D9M05Ho5RqQsSnq1HqaMiQIWb16tUNsq7nvt7J01/tYPEd59M1NqxB1ukxxsC8m2HLJ/CL+ZB0ntMRKaUaCRFZY4wZ4m6a3kldjWlndyIwwI/nv0l2OpTTE4HLnoPILlai0K7BlVINQBNENaJDWzLr/M58su4AH6xOOf0CTmsZBtfMhtIieO96KD3qdERKqUZOE0QNfj+6OyO7RPHgp5vYk1XodDinF9vTurLpwM8wX58foZQ6M5ogauDvJzxzzQAC/Pz4a2PohgOg5yS48AHY+D788JzT0SilGjFNEKcR2zqI317Ula+3Zfj+Za+Vzr8Lek+Grx6CnYudjkYp1UhpgqiFG89JJDEqmEc/20JpeSO410DEen5E275Wo3XWTqcjUko1QpogaqFlgD8PTOpNckYBs1fsczqc2gkMgeveBf8AeHeq3mmtlKozTRC1dHGvWM7rFs2/vtpB6uEip8OpnYhOcO271mWvc6dB2TGnI1JKNSKaIGpJRHjo0j4YYMq/f2BdSq7TIdVOp+Ew5QXY/yN8erte2aSUqjVNEHXQNTaUj389kuBAf6a9uoIfdmU5HVLt9LsKLnoQNn6gjytVStWaJog66hobxrxfjSC+TStu+u8q1jeWM4nz7oSB02HpE7BujtPRKKUaAU0Q9RAbFsTcmSNoExzIvR9uaDxXNl3yDCRdYD2Jbte3TkeklPJxmiDqKTIkkL9M7sO2Q0d49bvdTodTO/4tYOpbENMD5l4PaWucjkgp5cNqlSBE5Pci0tp+bsN/RGStiIz1dHC+bmyfdkzo245nF+9kb2PoigOgVQRM/xBComH2VZC5w+mIlFI+qrZnEDcbY/KBsUAMcBPwuMeiakQevqwPgf5+/OmTjb79BDpXYe1gxsfgFwBvXw55qU5HpJTyQbVNEJXPjp4I/NcYsx73z5Nudtq2DuLeCT35PjmbD9c2om62o7rA9HlwLB/evkJvpFNKnaK2CWKNiCzCShBfikgY0AhaZr1j2rBODE5ow18XbCG7oBHdjNb+LLhuDhzeC7OvhOI8pyNSSvmQ2iaIW4D7gKHGmCKgBVY1kwL8/ITHr+hH4bEyHvhkU+O4qqlS4rkw9U04tMFqkzh2xOmIlFI+orYJYgSw3RiTKyLTgQcAPdx00a1tGHeN7cHCTYe4/tWfyCkscTqk2usxAa563bqq6Z2pUNJIGtyVUh5V2wTxIlAkImcB9wD7gLc8FlUjddsFXXj22gGsS83l7g/WN55Ga7C6B7/yVUhZAe9eAyWNpL8ppZTH1DZBlBnr124y8Kwx5lkgzHNhNV6TB8Rx7/iefL0to3E1WgP0vRIufxn2Lrc69ystdjoipZSDapsgjojI/cAMYIGI+GO1Qyg3bhqZyLDESB78ZBOLNh9yOpy66T8VJv8bdi+B96ZrD7BKNWO1TRDXAMew7oc4BMQB//BYVI2cn5/w/PUD6d42lNtmr+GlpbsaV3XTwOvh0mcg+St4/wZNEko1U7VKEHZSeAcIF5FLgGJjjLZB1KCyv6aJ/drz+MJt/N/HjehGOoDBN8Kkf8KOhVa3HFrdpFSzU9uuNqYCK4GrganATyJylScDawpaBfrz/64dyMzzOzNnZQrfbMtwOqS6GfpLuPRZSF4Mc67VhmulmpnaVjH9CeseiBuMMb8AhgEPei6spsPPT7h7XA+SokN4fOE2yhrTPRJgnUlMecFqk3h3KhwrcDoipZSX1DZB+BljXA9/s+uwbLPXwt+Pe8b1YGdGAb+d8zNfbDrUuKqbBkyDK16Ffd/bd1znOx2RUsoLavsj/4WIfCkiN4rIjcAC4HPPhdX0jO/bjhtGJPDDrmxmzV7DfR9upKSsEZ1N9L/aupkudRW8dRkUNpKn6Sml6k1qeyQrIlcC52B10rfMGPOxJwOrjyFDhpjVq1c7HUaNyisMzy7ewXPfJHNxz1hemjGYFv6N6GRs+xfwwQ0Q3tHqETaio9MRKaXOgIisMcYMcTutUVV1nEZjSBCV3v5xLw9+upkrBsbx1NVn4efXiDrH3fejdbd1YIiVJGJ7Oh2RUqqeakoQNR66isgREcl3MxwREa2IPgMzRiRyx5jufPRzGo99vrVxtUkkjICbPgdTDv8dD6mNIykrpeqmxgRhjAkzxrR2M4QZY1p7K8im6rcXdeXGkYn8Z/keHluwleLScqdDqr12feHmLyEoHN68DJK/djoipVQDa0SV302PiPDnS3ozY3gCry3fw6TnviM5oxF1tx2ZBDcvgsjOVpXTpo+cjkgp1YA0QTjMz094dEpf3rx5GHlHy7j83z/w1ZZ0p8OqvbC2cONnED8U5t0Mq15zOiKlVAPRBOEjLugew6e/OYf4yGBufWs1v3xzNVmN5el0rSJgxkfQfTwsuBO+eQwaU5uKUsotTRA+JC6iFZ/efg73TejJdzszufyF70nOaCR3LrdoBdfMhoEzYNmT8MmvobzU6aiUUmdAE4SPCQzwY9YFXZg7czhFx8qZ9Nx3PL1oO0UlZU6Hdnr+AXDZ/4NR98P6d+2uORpRm4pS6iQeTRAiMl5EtotIsojc52a6iMhz9vQNIjLIZVqEiMwTkW0islVERngyVl8zsFMbFvzuPMb3bcdz3yRz0VNL+XRdmu9fDisCo+6Dy56H3UvhvxPgSCN7JoZSCvBggrAfKvRvYALQG7hORHpXmW0C0M0eZmI92rTSs8AXxpiewFnAVk/F6qvahQfx7LUDmTdrBNFhgfx+7jqueulH9mc3gl5VB82Aae9B9m54bQxkbnc6IqVUHXnyDGIYkGyM2W2MKQHmYj2y1NVk4C1jWQFEiEh7EWkNnA/8B8AYU2KMyfVgrD5tSGIk828/lyev7E9yRgHXvtJIkkS3MdYVTmVH4T9jYe/3TkeklKoDTyaIOCDF5X2qPa4283QGMoH/isjPIvKaiIS424iIzBSR1SKyOjMzs+Gi9zF+fsLUoR1599azKSwpZ8y/lnLdKytYsTvb6dBqFjcIbvkKQmLg7Smw4X2nI1JK1ZInE4S7zoWqVqBXN08AMAh40RgzECgETmnDADDGvGKMGWKMGRITE3Mm8TYKfTqEM2/WCKad3YmUw0Vc/9pPvLx0l2/3DBuZBLcsgvhh8NGtsOQJvQxWqUbAkwkiFXDt6jMeOFDLeVKBVGPMT/b4eVgJQwHd2obx0KV9WPj787i4Zyx/X7iNC59awkdrU323ETs40urYr/+1sORv1mWwZSVOR6WUqoEnE8QqoJuIJIlIIHAtML/KPPOBX9hXMw0H8owxB+1nYKeISA97vouBLR6MtVEKC2rByzMG8+bNw4gODeSO99cz9eUf2Xwgz+nQ3AsIhMtfOnEZ7Owr4Ohhp6NSSlXDo919i8hE4BnAH3jdGPOYiMwCMMa8JCICPA+MB4qAm4wxq+1lBwCvAYHAbntajb8mjam774ZWUWGYtyaVx7/YRm5RCdOHJ3DnmB6EB7dwOjT31r8Hn95uVT9Ne9/6q5TyOn0eRDOSV1TK019t5+0V+whpGcCoHrHMGJ7AsKRIp0M71d7lMPd68AuA6+ZCx6FOR6RUs6MJohnafCCP/36/l2+3ZZBdWMK1Qzty87lJdG8b5nRoJ8vaCe9cZd1Md/nL0GeK0xEp1axogmjGjpaU8/RX23n9+72UVxiGJUXyx9HdGdElyunQTijMgrnTIOUnGPMXGPk7645spZTHaYJQZB45xqfr0nj1u92k5x9jeOdI7hrbgyGJPlL1VFoMn8yCzR/D4Jtg4lNW305KKY/SBKGOKy4tZ87K/bywZBeZR44xsV87br+wK306hDsdGlRUwDePwvKnocvFcPUbEKQPLlTKkzRBqFMUlZTx6rI9vLxsF0Ul5fTp0JrhnaO4blgnusaGOhvcmjfhsz9CTE+4/n0Ij3c2HqWaME0Qqlp5R0v5YHUKi7ems3Z/LqXlFVzSvwO/vairsw3au76B92+AFsFWp38dBjgXi1JNmCYIVSvZBcd4bfke3vphL0Wl5Uzs256bz02kb1w4LQP8vR9Q+hbrmRJFOXDV69BjvPdjUKqJ0wSh6uRwYQn/Wb6HN37YS8GxMlr4C9cN68Rd43rQOsjLN94dOQRzroWD62H84zBspl7hpFQD0gSh6iWvqJTvd2WxbEcm761OIbxVC64YGM91wzrSzZvVTyWF8OGtsH0BDJgOk56yHnGqlDpjmiDUGduYmsdLy3axaPMhSssNQxPb8OsLuzKqewzijSP6inJY8rj1vOv2Z8HUt6FNgue3q1QTpwlCNZjsgmN8tDaNN37YS1ruUaJDAxmaGMn4vu0Y27sdrQI93Fax/Qv4aCb4+cGVr0HX0Z7dnlJNnCYI1eBKyipYsPEA3+3MYvnOLDKOHCMyJJCbz0lkQr/2dI4O8dyZRfYueG8GZGyxeoY9/y7wc6ARXakmQBOE8qiKCsOKPdm8vHQ3S3dYT/Ub0DGCByb18tyd2iWF8NkdsGEuJJ4HV7wKrdt7ZltKNWGaIJTXpOQUsXhrOi8t3UV6/jF6tA1jUv/2XNK/PZ1jGvgGPGNg/RxYcKfVaD3lReg+rmG3oVQTpwlCeV1RSRnz1qTy2fqDrNybA0DPdmFM6teeif3b06Uhk0XmDph3M6RvhOG3w+iHIKBlw61fqSZME4Ry1MG8o3y+8RCfbzzImn3WM5/i27Ti4p6xTB+e0DCXzJYWw1cPwspXoG1fq+vwdn3PfL1KNXGaIJTPOJRXzFdbDvHdziyW7MikpKyCc7pGcf3ZCVzYI/bMr4La/gXM/631KNOL/mR1Ha4N2EpVSxOE8knZBceYuyqFd1bs40BeMa1a+HNRz1gm9GvHRT1jCQ6sZ3ffhdnw2R9g63zoOBwufxEiOzdo7Eo1FZoglE8rK69g5Z4cFmw8yJebD5FVUEJQCz9GdbeSxcW92hLaso7JwhjY8D58fjdUlMG4x2DwjdpNh1JVaIJQjUZ5hWHV3hwWbjzIwk2HyDhyjMAAPy7oHsNEO1nUqT+ovFT45FewZxl0GweX/T8Ia+u5D6BUI6MJQjVKFRWGNfsP8/nGgyzceIhD+cUE+vsxsmsUo3u1ZUzvtrRtHVSbFVmN14sfsi6HHfc3OOs6PZtQCk0QqgmoqDD8nJLLwo0HWbQlnf05RQD0jw9nTK+2jO7dlp7twmq+eztzh9WAnbICOo+CS56ByCSvxK+Ur9IEoZoUYwzJGQUs2pLO4q3prEvJxRiIi2jF6F6xjO7dlrOToggM8Dt14YoKWPM6fPWw1TZx0Z/g7F/p869Vs6UJQjVpGUeK+WZrBou3prM8OYvi0gpCWwZwfvdoLuwRy6gescSEVblxLi8VFtwFOxZC+wFW20T7/o7Er5STNEGoZuNoSTk/7Mpi8dYMvt6aTsaRY4BVFTW6V1vG9mlLj7Z2VZQxsOUT60qnohwYdqvV+V+rCEc/g1LepAlCNUvGGLYczGfJ9ky+2ZbB2v2HMQY6RQZzUc9Yzu8ezfDOUQSX5cO3j8Hq16FVJIx+GAZcb3UprlQTpwlCKayqqK+3ZrBo8yF+3J1NcWkFgf5+DE1qwwXdYxgTmU7iT48gKSsgbjBM+AfED3Y6bKU8ShOEUlUUl5azeu9hlu7IYOmOTHakFwDQNiyQP8Su4/Kslwg6lgUDp8NFD0JYO4cjVsozNEEodRoH846ybEcmy3Zk8d3OTCqK8/ldwMfcFPAl+AWQ1e+XxI6/B/9W4U6HqlSD0gShVB2UlVewPjXPOrPYuoGJma9xmf+P5BDG1zE3IENu4dyeHWgXXoub9JTycZoglDoDhwtL2LhqCe1X/Z1uhWvZXxHDU2XXsDVqNCO6xjCySxTDO0cRERzodKhK1ZkmCKUagjGY5MUcW/ggQTlbSWmRyD+PXc6nJYNB/OjdvjUju0Qxsms0wxIjCalrB4NKOUAThFINqaICNn8ESx6H7J0UtenBt+1uZnZuP9bsz6ekvIIAP2FQQhvO7xbNed1i6BsXjr+f9v2kfI8mCKU8oaIcNn0IS5+A7GRo25eSc+9hZcsRLN+Vw/LkTDal5QMQEdyCc7pGM7JLFGfFR9C9bZj7rkCU8jJNEEp5UnnZiUSRswva9YML7oUek8gqKuX75Cy+22ldHZWeb93ZHejvR8/2YfSNC2dYYiTnd48hMkTbMJT3aYJQyhvKy2DjB7DsScjZDdHd4Zw/QL+rISAQYwz7sovYmJbHprQ8NtrDkeIyRKB/fAQX9ojhvG4xdGsbWrfnXihVT44lCBEZDzwL+AOvGWMerzJd7OkTgSLgRmPMWpfp/sBqIM0Yc8nptqcJQvmE8jKrj6flz0D6RmgdByN+A4N+AS1DT561wrAxLY8l2zNYsj2T9alWz7QAHcKDGJYUybCkKIYlRdIlJqTm7syVqgdHEoT9474DGAOkAquA64wxW1zmmQj8FitBnA08a4w522X6HcAQoLUmCNXoGAPJX8Pyf8G+5RAUAcNmwtBfVvtUu5zCElbtzWFPViEbU/P4aU8OWQVWtVRUSKCdMKyhZ7vW2vCtzlhNCcKT1+ENA5KNMbvtIOYCk4EtLvNMBt4yVpZaISIRItLeGHNQROKBScBjwB0ejFMpzxCBbqOtIWWVlSiWPWn97XsFnD0L4gadtEhkSCDj+pzo1sMYw56sQlbuyWHlnhx+2pPDwk2HAAhtGcCAjhEM6hTBoIQ2DOzUhvBWWi2lGo4nE0QckOLyPhXrLOF088QBB4FngHuAsJo2IiIzgZkAnTp1OqOAlfKYjkPhunche5f1+NOf34EN70H8MBg+C3pdBv6n/riLCJ1jQukcE8q1w6z9Oy33KKv25LBm32HW7DvM898mU2FXBHSOCWFgxzYM6BTBwI4R9GgXRgt/vVpK1Y8nE4S7c9+q9Vlu5xGRS4AMY8waERlV00aMMa8Ar4BVxVSPOJXynqguMOEJuPBPsO5dWPkyzLsZwtrDwBkwaAZE1HygExfRiriBcUwZGAdAwbEyNqTksnb/Ydal5LJkewYfrk0FoGWAH/3iwjmrYwQD7CG+TStty1C14sk2iBHAw8aYcfb7+wGMMX93medlYIkxZo79fjswCvgdMAMoA4KA1sBHxpjpNW1T2yBUo1NRAclfWWcVyV9b47peDINugB4T3J5VnI4xhtTDR/k5JZd1+3NZn5rLprQ8jpVVAFZbhmvCOCs+gvBgrZpqrpxqpA7AaqS+GEjDaqSeZozZ7DLPJOA3nGikfs4YM6zKekYBd2kjtWrycvfDz7OtIT8NQmJhwDQ46zqI7XlGqy4tr2D7oSP8nJLL+pRc1qXksiuz4PgVU52jQ05KGj3ahRHUwr8BPpTydU5e5joRqy3BH3jdGPOYiMwCMMa8ZF/m+jwwHusy15uMMaurrGMUmiBUc1JRDsmLYc2bsOMLMOXQrj/0vwb6Xgmt2zfIZvKLS9mYmsc6O2GsS8kl035Ea4Cf0DU2lL5x4fTt0Jq+ceH0at9a+5dqgvRGOaUaq4IM2PSR1aB9YC0g0PkC6DcVek5q0OdnG2M4mFfM+pRcNh3IY/OBfDal5ZFVUAJYF2UlRYfQt0M4feNa06dDOH06tNZebBs5TRBKNQVZybDxfStZHN4Lfi2sZNHrUuh5CYREN/gmjTFkHDnGprQ8NqXls9lOHGm5R4/PE9+m1clJI641sWH6rIzGQhOEUk2JMZC6GrbOt4bDe0H8IOEcK1n0mHDaK6HOVE5hCZsPnJw09mQVHp8eG9aSvnHWGUYfO3nERejVU75IE4RSTZUxcGgjbP2flSwyt1njY3pB97HQbSx0PLteV0PV1ZHiUrYcyGfTATtppOWzM+PI8Xs0WgcF0KNdGN3bhp342zaMNtpJoaM0QSjVXGTthB1fws5FsO8HqCiFluHQ5UIrWXQbA6GxXgvnaEk52w5ZSWPbwXx2pB9h+6Ej5BeXHZ8nNqwlPdpZyaJHO2voFhtGq0C9isobNEEo1RwV58OepXbC+AoKrC466DAQuo6GzqMgfigEtPRqWMYY0vOPse2QlTC2HTrCjvQj7EwvOH6vhggkRAbbCaP18eSRGBVMgN4Z3qA0QSjV3BkDhzZYZxY7FkHaajAV0CIYEkZayaLzKIjtA37O/ACXVxj2ZRey/dARtttnGtvTj7A3q/B4NVVggB9dY0Lp2S6Mbm3D6BobStfYUDpFBmvHhfWkCUIpdbKjubDve9i9BHYvhazt1vjgKEi64ETCaJPgXIy24tJykjMK2G6faWw7ZCWPQ/nFx+cJDPCjc3QIXWJD6WYnja6xoSRFh9AyQKuqaqIJQilVs/wDVqLYvcQaKquj2iRC4rmQcK51puEDCaNSfnEpuzIKSHYdMgvYn1N0/A5xP4GEqBC6xITSrW0oXWOsxNElNpRQvekP0AShlKoLYyBrx4lkse8HKM61poV3tBJFwkjrstqorlaDgQ8pLi1nd2YhOzOOWAkks4Cd6QXszS6ktPzE712H8CC6xIbSJSaUjpHBxLdpRafIYBKjQppVA7kmCKVU/VVUQOZWK1HsXW79LcywpoXEnkgWCSMhthf4+eaPa2l5BftzitiZXsCuTOuMY2fGEfZkFlJYUn7SvB3Cg0iKCaFTZAgJUcEkRAbTKSqYhKiQJnfmoQlCKdVwjLGea7HPThZ7v4d8q3txAsMgfrB170X8MIgf0qDdgXiCMYbcolJSDhexL7uIPVmF7MkqZHdWISk5ReQUlpw0f1RIoJUsIoPpFBlMp6gTSSQmrGWjuxlQE4RSyrMO74P9P0LKSkhdCembraukAGJ6WpfTdjwbOg6DqG6OXSlVH/nFpezPLmJ/jpVA9ucUsi/ben0w7+jxK6wAWrXwt5OGlTASoqwE0smuwvLFhzdpglBKedexI5C29kTCSFl5oh0jKALiBluPW+0wEDoMarAear2tpKyC1MNF7MspOiWJ7M8pori04vi8fgIdIlpZScOHqq40QSilnFVRAdnJkPKTlTDS1kLGVqsrc4DQdi4Jwx480PmgN1V2dGidbRQeTx5WMinkcFHpSfNHhQQebyyPa9OK+DbBxEe0Ov4+ONAzCUQThFLK95QUWf1IHfjZ6sr8wM9WVyGVTyYO7wRxLgmjXX8IjnQ05IZUXdVVWu5RDuQePemKK4DIkEDiKhPG8cQRbL2ObEXroPr1t6UJQinVOBTnw8H1dtKwE8fhvSemt46Hdv1OHiISGlWbRm1UVFhnH2m5RaQePnp8SMs9SurhItIOHz3eLQlYHSFueHhcvbZVU4JoWtdrKaUat6DWkHSeNVQqyrGSRvomOLjBOuvYuehE9VTL1tC2L7TreyJpxPSCFo33mRR+fkK78CDahQcx2M29icYYsgpKjieMo1Uu020oegahlGp8So9abRiHNp4Y0jdBSYE1XfwhpoeVOGJ7nRjCOzW5s40zpWcQSqmmpUUrq1E7btCJcRUVcHiPS9LYYN2nsfF9l+VCILanlSxiKhNHbwhr53N3hPsCTRBKqabBzw+iulhDnyknxhfnQeZ2yNhinXVkbLF6tP159ol5giJczjR6n0ggIVHe/hQ+RROEUqppCwq3btDrOOzk8YVZdsLYanUlkrEVNn0Ixa+fmCc4CqK7Q3Q3+6/9OiLBZ7sUaUiaIJRSzVNI9KkN4sbAkYP22cY2yN5pXXq7fSGsfevEfP4trY4KqyaO6G4QGOL9z+IhmiCUUqqSCLTuYA1dR588rSjHShZZO+xhp/088PknuhUB61LcGDtpRHWFyM5WtVd4x0Z31qEJQimlaiM4EjqdbQ2uyo5Bzh6XxGEPP88+cVUVgF8L63kakV2spBHZGaLsv+GdwN/3fo59LyKllGpMAlraV0b1PHm8MXDkEOTsdhl2WX/3LofSwhPz+gVY7RqVZxuVCSSyM0R0Av/63SV9pjRBKKWUJ4hYnRC2bg+J55w8zRgoyDg5aeTstrpR3//jyWce4m8liTaJ7gcPdqeuCUIppbxNBMLaWkPCiJOnGQOFmScnjZzdVpcjWz6Fozknz195ie7NXzR4mJoglFLKl4hAaKw1dBp+6vTiPOv5G7n7rKRxeC+Ul546XwPQBKGUUo1JUDi0728NHqadkiillHJLE4RSSim3NEEopZRySxOEUkoptzRBKKWUcksThFJKKbc0QSillHJLE4RSSim3mtQzqUUkE9hXz8WjgawGDKehaFx156uxaVx1o3HVXX1iSzDGxLib0KQSxJkQkdXVPbjbSRpX3flqbBpX3WhcddfQsWkVk1JKKbc0QSillHJLE8QJrzgdQDU0rrrz1dg0rrrRuOquQWPTNgillFJu6RmEUkoptzRBKKWUcqvZJwgRGS8i20UkWUTuczCOjiLyrYhsFZHNIvJ7e/zDIpImIuvsYaJD8e0VkY12DKvtcZEi8pWI7LT/tvFyTD1cymWdiOSLyB+cKDMReV1EMkRkk8u4astHRO6397ntIjLOgdj+ISLbRGSDiHwsIhH2+EQROepSdi95Oa5qvztvlVk1cb3nEtNeEVlnj/dmeVX3G+G5/cwY02wHwB/YBXQGAoH1QG+HYmkPDLJfhwE7gN7Aw8BdPlBWe4HoKuOeBO6zX98HPOHwd3kISHCizIDzgUHAptOVj/29rgdaAkn2Pujv5djGAgH26ydcYkt0nc+BMnP73XmzzNzFVWX6P4E/O1Be1f1GeGw/a+5nEMOAZGPMbmNMCTAXmOxEIMaYg8aYtfbrI8BWIM6JWOpgMvCm/fpNYIpzoXAxsMsYU9876c+IMWYZUOVp8tWWz2RgrjHmmDFmD5CMtS96LTZjzCJjTJn9dgUQ76nt1yWuGnitzGqKS0QEmArM8cS2a1LDb4TH9rPmniDigBSX96n4wI+yiCQCA4Gf7FG/sasCXvd2NY4LAywSkTUiMtMe19YYcxCsnReIdSg2gGs5+Z/WF8qsuvLxtf3uZmChy/skEflZRJaKyHkOxOPuu/OVMjsPSDfG7HQZ5/XyqvIb4bH9rLknCHEzztHrfkUkFPgQ+IMxJh94EegCDAAOYp3eOuEcY8wgYAJwu4ic71AcpxCRQOAy4AN7lK+UWXV8Zr8TkT8BZcA79qiDQCdjzEDgDuBdEWntxZCq++58pcyu4+QDEa+Xl5vfiGpndTOuTmXW3BNEKtDR5X08cMChWBCRFlhf/DvGmI8AjDHpxphyY0wF8CoerIqoiTHmgP03A/jYjiNdRNrbsbcHMpyIDStprTXGpNsx+kSZUX35+MR+JyI3AJcA1xu70tqujsi2X6/Bqrfu7q2YavjuHC8zEQkArgDeqxzn7fJy9xuBB/ez5p4gVgHdRCTJPgq9FpjvRCB23eZ/gK3GmKddxrd3me1yYFPVZb0QW4iIhFW+xmrg3IRVVjfYs90AfOrt2GwnHdX5QpnZqiuf+cC1ItJSRJKAbsBKbwYmIuOBe4HLjDFFLuNjRMTfft3Zjm23F+Oq7rtzvMyA0cA2Y0xq5Qhvlld1vxF4cj/zRuu7Lw/ARKyrAXYBf3IwjnOxTv82AOvsYSLwNrDRHj8faO9AbJ2xroZYD2yuLCcgCvga2Gn/jXQgtmAgGwh3Gef1MsNKUAeBUqwjt1tqKh/gT/Y+tx2Y4EBsyVj105X72kv2vFfa3/F6YC1wqZfjqva781aZuYvLHv8GMKvKvN4sr+p+Izy2n2lXG0oppdxq7lVMSimlqqEJQimllFuaIJRSSrmlCUIppZRbmiCUUkq5pQlCKR8gIqNE5DOn41DKlSYIpZRSbmmCUKoORGS6iKy0+/5/WUT8RaRARP4pImtF5GsRibHnHSAiK+TEMxfa2OO7ishiEVlvL9PFXn2oiMwT6zkN79h3zirlGE0QStWSiPQCrsHquHAAUA5cD4Rg9QU1CFgKPGQv8hZwrzGmP9bdwZXj3wH+bYw5CxiJddcuWL1z/gGrH//OwDke/khK1SjA6QCUakQuBgYDq+yD+1ZYHaNVcKIDt9nARyISDkQYY5ba498EPrD7tIozxnwMYIwpBrDXt9LY/fzYTyxLBJZ7/FMpVQ1NEErVngBvGmPuP2mkyINV5qup/5qaqo2OubwuR/8/lcO0ikmp2vsauEpEYuH4s4ATsP6PrrLnmQYsN8bkAYddHiAzA1hqrP77U0Vkir2OliIS7M0PoVRt6RGKUrVkjNkiIg9gPVnPD6u3z9uBQqCPiKwB8rDaKcDqevklOwHsBm6yx88AXhaRv9jruNqLH0OpWtPeXJU6QyJSYIwJdToOpRqaVjEppZRyS88glFJKuaVnEEoppdzSBKGUUsotTRBKKaXc0gShlFLKLU0QSiml3Pr/a6t+pIcamycAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot of loss vs epoch for train and test dataset\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title(\"Plot of loss vs epoch for train and test dataset\")\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
