{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8d3c484",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "from Energy_Models import ConvLstm as CL\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42edfa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('D:\\College\\Final\\Gpr\\Datasets\\household_power_consumption.txt',sep=';', \n",
    "                 parse_dates={'date_time' : ['Date', 'Time']}, infer_datetime_format=True, \n",
    "                 low_memory=False, na_values=['nan','?'], index_col='date_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcb3cc91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Global_active_power</th>\n",
       "      <th>Global_reactive_power</th>\n",
       "      <th>Voltage</th>\n",
       "      <th>Global_intensity</th>\n",
       "      <th>Sub_metering_1</th>\n",
       "      <th>Sub_metering_2</th>\n",
       "      <th>Sub_metering_3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:24:00</th>\n",
       "      <td>4.216</td>\n",
       "      <td>0.418</td>\n",
       "      <td>234.84</td>\n",
       "      <td>18.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:25:00</th>\n",
       "      <td>5.360</td>\n",
       "      <td>0.436</td>\n",
       "      <td>233.63</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:26:00</th>\n",
       "      <td>5.374</td>\n",
       "      <td>0.498</td>\n",
       "      <td>233.29</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:27:00</th>\n",
       "      <td>5.388</td>\n",
       "      <td>0.502</td>\n",
       "      <td>233.74</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:28:00</th>\n",
       "      <td>3.666</td>\n",
       "      <td>0.528</td>\n",
       "      <td>235.68</td>\n",
       "      <td>15.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Global_active_power  Global_reactive_power  Voltage  \\\n",
       "date_time                                                                  \n",
       "2006-12-16 17:24:00                4.216                  0.418   234.84   \n",
       "2006-12-16 17:25:00                5.360                  0.436   233.63   \n",
       "2006-12-16 17:26:00                5.374                  0.498   233.29   \n",
       "2006-12-16 17:27:00                5.388                  0.502   233.74   \n",
       "2006-12-16 17:28:00                3.666                  0.528   235.68   \n",
       "\n",
       "                     Global_intensity  Sub_metering_1  Sub_metering_2  \\\n",
       "date_time                                                               \n",
       "2006-12-16 17:24:00              18.4             0.0             1.0   \n",
       "2006-12-16 17:25:00              23.0             0.0             1.0   \n",
       "2006-12-16 17:26:00              23.0             0.0             2.0   \n",
       "2006-12-16 17:27:00              23.0             0.0             1.0   \n",
       "2006-12-16 17:28:00              15.8             0.0             1.0   \n",
       "\n",
       "                     Sub_metering_3  \n",
       "date_time                            \n",
       "2006-12-16 17:24:00            17.0  \n",
       "2006-12-16 17:25:00            16.0  \n",
       "2006-12-16 17:26:00            17.0  \n",
       "2006-12-16 17:27:00            17.0  \n",
       "2006-12-16 17:28:00            17.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2bae894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 2075259 entries, 2006-12-16 17:24:00 to 2010-11-26 21:02:00\n",
      "Data columns (total 7 columns):\n",
      " #   Column                 Dtype  \n",
      "---  ------                 -----  \n",
      " 0   Global_active_power    float64\n",
      " 1   Global_reactive_power  float64\n",
      " 2   Voltage                float64\n",
      " 3   Global_intensity       float64\n",
      " 4   Sub_metering_1         float64\n",
      " 5   Sub_metering_2         float64\n",
      " 6   Sub_metering_3         float64\n",
      "dtypes: float64(7)\n",
      "memory usage: 126.7 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51b1d02e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2075259, 7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d0525ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Global_active_power      25979\n",
       "Global_reactive_power    25979\n",
       "Voltage                  25979\n",
       "Global_intensity         25979\n",
       "Sub_metering_1           25979\n",
       "Sub_metering_2           25979\n",
       "Sub_metering_3           25979\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0db1aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling missing values by the value of one day before \n",
    "def fill_missing(data):\n",
    "    one_day = 24*60\n",
    "    for row in range(data.shape[0]):\n",
    "        for col in range(data.shape[1]):\n",
    "            if np.isnan(data[row,col]):\n",
    "                data[row,col] = data[row-one_day,col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb48f24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_missing(df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24a096d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Global_active_power      0\n",
       "Global_reactive_power    0\n",
       "Voltage                  0\n",
       "Global_intensity         0\n",
       "Sub_metering_1           0\n",
       "Sub_metering_2           0\n",
       "Sub_metering_3           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64af1484",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('new_household_power_consumption.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f324b105",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('new_household_power_consumption.csv',parse_dates=['date_time'], index_col= 'date_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "438c49ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Global_active_power</th>\n",
       "      <th>Global_reactive_power</th>\n",
       "      <th>Voltage</th>\n",
       "      <th>Global_intensity</th>\n",
       "      <th>Sub_metering_1</th>\n",
       "      <th>Sub_metering_2</th>\n",
       "      <th>Sub_metering_3</th>\n",
       "      <th>sub_metering_remaining</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.075259e+06</td>\n",
       "      <td>2.075259e+06</td>\n",
       "      <td>2.075259e+06</td>\n",
       "      <td>2.075259e+06</td>\n",
       "      <td>2.075259e+06</td>\n",
       "      <td>2.075259e+06</td>\n",
       "      <td>2.075259e+06</td>\n",
       "      <td>2.075259e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.089418e+00</td>\n",
       "      <td>1.236871e-01</td>\n",
       "      <td>2.408364e+02</td>\n",
       "      <td>4.618401e+00</td>\n",
       "      <td>1.118474e+00</td>\n",
       "      <td>1.291131e+00</td>\n",
       "      <td>6.448635e+00</td>\n",
       "      <td>9.298722e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.054678e+00</td>\n",
       "      <td>1.125933e-01</td>\n",
       "      <td>3.240051e+00</td>\n",
       "      <td>4.433165e+00</td>\n",
       "      <td>6.141460e+00</td>\n",
       "      <td>5.796922e+00</td>\n",
       "      <td>8.433584e+00</td>\n",
       "      <td>9.561278e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>7.600000e-02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.232000e+02</td>\n",
       "      <td>2.000000e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-2.400000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.080000e-01</td>\n",
       "      <td>4.800000e-02</td>\n",
       "      <td>2.389900e+02</td>\n",
       "      <td>1.400000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.800000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.020000e-01</td>\n",
       "      <td>1.000000e-01</td>\n",
       "      <td>2.410000e+02</td>\n",
       "      <td>2.600000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>5.500000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.526000e+00</td>\n",
       "      <td>1.940000e-01</td>\n",
       "      <td>2.428700e+02</td>\n",
       "      <td>6.400000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.700000e+01</td>\n",
       "      <td>1.036667e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.112200e+01</td>\n",
       "      <td>1.390000e+00</td>\n",
       "      <td>2.541500e+02</td>\n",
       "      <td>4.840000e+01</td>\n",
       "      <td>8.800000e+01</td>\n",
       "      <td>8.000000e+01</td>\n",
       "      <td>3.100000e+01</td>\n",
       "      <td>1.248333e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Global_active_power  Global_reactive_power       Voltage  \\\n",
       "count         2.075259e+06           2.075259e+06  2.075259e+06   \n",
       "mean          1.089418e+00           1.236871e-01  2.408364e+02   \n",
       "std           1.054678e+00           1.125933e-01  3.240051e+00   \n",
       "min           7.600000e-02           0.000000e+00  2.232000e+02   \n",
       "25%           3.080000e-01           4.800000e-02  2.389900e+02   \n",
       "50%           6.020000e-01           1.000000e-01  2.410000e+02   \n",
       "75%           1.526000e+00           1.940000e-01  2.428700e+02   \n",
       "max           1.112200e+01           1.390000e+00  2.541500e+02   \n",
       "\n",
       "       Global_intensity  Sub_metering_1  Sub_metering_2  Sub_metering_3  \\\n",
       "count      2.075259e+06    2.075259e+06    2.075259e+06    2.075259e+06   \n",
       "mean       4.618401e+00    1.118474e+00    1.291131e+00    6.448635e+00   \n",
       "std        4.433165e+00    6.141460e+00    5.796922e+00    8.433584e+00   \n",
       "min        2.000000e-01    0.000000e+00    0.000000e+00    0.000000e+00   \n",
       "25%        1.400000e+00    0.000000e+00    0.000000e+00    0.000000e+00   \n",
       "50%        2.600000e+00    0.000000e+00    0.000000e+00    1.000000e+00   \n",
       "75%        6.400000e+00    0.000000e+00    1.000000e+00    1.700000e+01   \n",
       "max        4.840000e+01    8.800000e+01    8.000000e+01    3.100000e+01   \n",
       "\n",
       "       sub_metering_remaining  \n",
       "count            2.075259e+06  \n",
       "mean             9.298722e+00  \n",
       "std              9.561278e+00  \n",
       "min             -2.400000e+00  \n",
       "25%              3.800000e+00  \n",
       "50%              5.500000e+00  \n",
       "75%              1.036667e+01  \n",
       "max              1.248333e+02  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sub_metering_remaining'] = (df.Global_active_power * 1000  / 60 ) - (df.Sub_metering_1 + df.Sub_metering_2 + df.Sub_metering_3)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7e78ed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1442, 8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# resample the data on daily basis\n",
    "df = df.resample('D').mean()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7481ac07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df):\n",
    "    \n",
    "    # compute split point\n",
    "    end_idx = df.shape[0]* 70 // 100\n",
    "    \n",
    "    train_data = df.iloc[:end_idx, : ]\n",
    "    test_data = df.iloc[end_idx:, :]\n",
    "    \n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "c0f53f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test\n",
    "X_train, X_test = train_test_split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "608cf763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1009, 8)"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "2fee9f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(train, test):\n",
    "    scaler = MinMaxScaler().fit(train)\n",
    "    return scaler.transform(train), scaler.transform(test), scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "f9f05ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, scaler = scale_data(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "ba29b78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_supervised(df):\n",
    "\n",
    "    input_features = []\n",
    "    ouput_feature = []\n",
    "    \n",
    "    len_df = df.shape[0]\n",
    "    \n",
    "    for i in range(len_df):\n",
    "        \n",
    "        end_idx = i + 1 \n",
    "        \n",
    "        if end_idx > len_df-1:\n",
    "            break\n",
    "            \n",
    "        input_x , output_y = df[i:end_idx, 1:], df[end_idx: end_idx+1, 0]\n",
    "        \n",
    "        input_features.append(input_x)\n",
    "        ouput_feature.append(output_y)\n",
    "    \n",
    "    return np.array(input_features), np.mean(np.array(ouput_feature), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "4f45e348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of (training data) input features : (1008, 1, 7) and ouput feature (1008,)\n"
     ]
    }
   ],
   "source": [
    "# Split the training data into input features and out feature\n",
    "X_train, Y_train = convert_to_supervised(X_train)\n",
    "print('Shape of (training data) input features : %s and ouput feature %s' % (X_train.shape, Y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "55022865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of (testing data) input features : (432, 1, 7) and ouput feature (432,)\n"
     ]
    }
   ],
   "source": [
    "# Split the testing data into input features and out feature\n",
    "X_test, Y_test = convert_to_supervised(X_test)\n",
    "print('Shape of (testing data) input features : %s and ouput feature %s' % (X_test.shape, Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "ff12d345",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps, n_features = X_train.shape[1], X_train.shape[2]\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10)\n",
    "convlstm_model = CL.ConvLstm(n_steps,n_features).getModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "f1060b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.reshape((X_train.shape[0],1,1,n_steps,X_train.shape[2]))\n",
    "X_test=X_test.reshape((X_test.shape[0],1,1,n_steps,X_test.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "02cccfde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "3/3 [==============================] - 9s 356ms/step - loss: 0.1037 - val_loss: 0.0805\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.0887 - val_loss: 0.0661\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.0738 - val_loss: 0.0522\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.0592 - val_loss: 0.0392\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.0459 - val_loss: 0.0278\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.0342 - val_loss: 0.0193\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.0259 - val_loss: 0.0153\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.0224 - val_loss: 0.0169\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.0239 - val_loss: 0.0202\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.0257 - val_loss: 0.0198\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.0246 - val_loss: 0.0174\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.0231 - val_loss: 0.0157\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.0223 - val_loss: 0.0152\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.0222 - val_loss: 0.0152\n",
      "Epoch 15/200\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.0225 - val_loss: 0.0152\n",
      "Epoch 16/200\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.0226 - val_loss: 0.0152\n",
      "Epoch 17/200\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.0225 - val_loss: 0.0151\n",
      "Epoch 18/200\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.0223 - val_loss: 0.0151\n",
      "Epoch 19/200\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.0221 - val_loss: 0.0152\n",
      "Epoch 20/200\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.0220 - val_loss: 0.0154\n",
      "Epoch 21/200\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.0220 - val_loss: 0.0154\n",
      "Epoch 22/200\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.0220 - val_loss: 0.0154\n",
      "Epoch 23/200\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.0219 - val_loss: 0.0153\n",
      "Epoch 24/200\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.0217 - val_loss: 0.0151\n",
      "Epoch 25/200\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.0216 - val_loss: 0.0149\n",
      "Epoch 26/200\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.0215 - val_loss: 0.0147\n",
      "Epoch 27/200\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.0211 - val_loss: 0.0145\n",
      "Epoch 28/200\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.0209 - val_loss: 0.0143\n",
      "Epoch 29/200\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.0204 - val_loss: 0.0142\n",
      "Epoch 30/200\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.0199 - val_loss: 0.0139\n",
      "Epoch 31/200\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.0193 - val_loss: 0.0135\n",
      "Epoch 32/200\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.0186 - val_loss: 0.0129\n",
      "Epoch 33/200\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.0177 - val_loss: 0.0121\n",
      "Epoch 34/200\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.0171 - val_loss: 0.0114\n",
      "Epoch 35/200\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.0160 - val_loss: 0.0107\n",
      "Epoch 36/200\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.0153 - val_loss: 0.0100\n",
      "Epoch 37/200\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.0143 - val_loss: 0.0097\n",
      "Epoch 38/200\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.0145 - val_loss: 0.0094\n",
      "Epoch 39/200\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.0143 - val_loss: 0.0092\n",
      "Epoch 40/200\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.0143 - val_loss: 0.0091\n",
      "Epoch 41/200\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.0139 - val_loss: 0.0091\n",
      "Epoch 42/200\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.0141 - val_loss: 0.0089\n",
      "Epoch 43/200\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.0134 - val_loss: 0.0088\n",
      "Epoch 44/200\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.0133 - val_loss: 0.0086\n",
      "Epoch 45/200\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.0139 - val_loss: 0.0087\n",
      "Epoch 46/200\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.0135 - val_loss: 0.0085\n",
      "Epoch 47/200\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.0133 - val_loss: 0.0087\n",
      "Epoch 48/200\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.0129 - val_loss: 0.0086\n",
      "Epoch 49/200\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.0128 - val_loss: 0.0085\n",
      "Epoch 50/200\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.0131 - val_loss: 0.0084\n",
      "Epoch 51/200\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.0129 - val_loss: 0.0084\n",
      "Epoch 52/200\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.0124 - val_loss: 0.0087\n",
      "Epoch 53/200\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.0126 - val_loss: 0.0084\n",
      "Epoch 54/200\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.0125 - val_loss: 0.0085\n",
      "Epoch 55/200\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.0126 - val_loss: 0.0083\n",
      "Epoch 56/200\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.0123 - val_loss: 0.0085\n",
      "Epoch 57/200\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.0123 - val_loss: 0.0087\n",
      "Epoch 58/200\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.0126 - val_loss: 0.0084\n",
      "Epoch 59/200\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.0120 - val_loss: 0.0082\n",
      "Epoch 60/200\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.0122 - val_loss: 0.0084\n",
      "Epoch 61/200\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.0122 - val_loss: 0.0088\n",
      "Epoch 62/200\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.0120 - val_loss: 0.0084\n",
      "Epoch 63/200\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.0122 - val_loss: 0.0081\n",
      "Epoch 64/200\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.0119 - val_loss: 0.0083\n",
      "Epoch 65/200\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.0120 - val_loss: 0.0085\n",
      "Epoch 66/200\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.0122 - val_loss: 0.0084\n",
      "Epoch 67/200\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.0120 - val_loss: 0.0083\n",
      "Epoch 68/200\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.0121 - val_loss: 0.0082\n",
      "Epoch 69/200\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.0120 - val_loss: 0.0082\n",
      "Epoch 70/200\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.0123 - val_loss: 0.0085\n",
      "Epoch 71/200\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.0119 - val_loss: 0.0082\n",
      "Epoch 72/200\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.0118 - val_loss: 0.0081\n",
      "Epoch 73/200\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.0119 - val_loss: 0.0081\n",
      "Epoch 74/200\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.0116 - val_loss: 0.0086\n",
      "Epoch 75/200\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.0121 - val_loss: 0.0084\n",
      "Epoch 76/200\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.0118 - val_loss: 0.0082\n",
      "Epoch 77/200\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.0119 - val_loss: 0.0081\n",
      "Epoch 78/200\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.0118 - val_loss: 0.0084\n",
      "Epoch 79/200\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.0117 - val_loss: 0.0083\n",
      "Epoch 80/200\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.0118 - val_loss: 0.0081\n",
      "Epoch 81/200\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.0119 - val_loss: 0.0082\n",
      "Epoch 82/200\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.0119 - val_loss: 0.0083\n",
      "Epoch 83/200\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.0117 - val_loss: 0.0082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/200\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.0117 - val_loss: 0.0081\n",
      "Epoch 85/200\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.0117 - val_loss: 0.0083\n",
      "Epoch 86/200\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.0116 - val_loss: 0.0081\n",
      "Epoch 87/200\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.0115 - val_loss: 0.0081\n",
      "Epoch 88/200\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.0117 - val_loss: 0.0081\n",
      "Epoch 89/200\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.0115 - val_loss: 0.0083\n",
      "Epoch 90/200\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.0118 - val_loss: 0.0081\n",
      "Epoch 91/200\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.0117 - val_loss: 0.0080\n",
      "Epoch 92/200\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.0116 - val_loss: 0.0081\n",
      "Epoch 93/200\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.0116 - val_loss: 0.0081\n",
      "Epoch 94/200\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.0115 - val_loss: 0.0083\n",
      "Epoch 95/200\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.0117 - val_loss: 0.0084\n",
      "Epoch 96/200\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.0118 - val_loss: 0.0079\n",
      "Epoch 97/200\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.0117 - val_loss: 0.0079\n",
      "Epoch 98/200\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.0117 - val_loss: 0.0085\n",
      "Epoch 99/200\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.0113 - val_loss: 0.0082\n",
      "Epoch 100/200\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.0115 - val_loss: 0.0079\n",
      "Epoch 101/200\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.0117 - val_loss: 0.0081\n",
      "Epoch 102/200\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.0115 - val_loss: 0.0080\n",
      "Epoch 103/200\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.0113 - val_loss: 0.0081\n",
      "Epoch 104/200\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.0115 - val_loss: 0.0083\n",
      "Epoch 105/200\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.0115 - val_loss: 0.0081\n",
      "Epoch 106/200\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.0115 - val_loss: 0.0078\n",
      "Epoch 107/200\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.0116 - val_loss: 0.0080\n",
      "Epoch 108/200\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.0113 - val_loss: 0.0085\n",
      "Epoch 109/200\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.0115 - val_loss: 0.0081\n",
      "Epoch 110/200\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.0114 - val_loss: 0.0080\n",
      "Epoch 111/200\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.0114 - val_loss: 0.0080\n",
      "Epoch 112/200\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.0115 - val_loss: 0.0081\n",
      "Epoch 113/200\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.0115 - val_loss: 0.0080\n",
      "Epoch 114/200\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.0114 - val_loss: 0.0079\n",
      "Epoch 115/200\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.0114 - val_loss: 0.0079\n",
      "Epoch 116/200\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.0113 - val_loss: 0.0081\n",
      "Epoch 117/200\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.0115 - val_loss: 0.0082\n",
      "Epoch 118/200\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.0113 - val_loss: 0.0079\n",
      "Epoch 119/200\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.0113 - val_loss: 0.0079\n",
      "Epoch 120/200\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.0113 - val_loss: 0.0081\n",
      "Epoch 121/200\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.0115 - val_loss: 0.0083\n",
      "Epoch 122/200\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.0113 - val_loss: 0.0077\n",
      "Epoch 123/200\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.0115 - val_loss: 0.0078\n",
      "Epoch 124/200\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.0114 - val_loss: 0.0082\n",
      "Epoch 125/200\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.0115 - val_loss: 0.0083\n",
      "Epoch 126/200\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.0114 - val_loss: 0.0077\n",
      "Epoch 127/200\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.0116 - val_loss: 0.0078\n",
      "Epoch 128/200\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.0113 - val_loss: 0.0084\n",
      "Epoch 129/200\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.0116 - val_loss: 0.0083\n",
      "Epoch 130/200\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.0114 - val_loss: 0.0077\n",
      "Epoch 131/200\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.0115 - val_loss: 0.0079\n",
      "Epoch 132/200\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.0113 - val_loss: 0.0082\n",
      "Epoch 133/200\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.0114 - val_loss: 0.0080\n",
      "Epoch 134/200\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.0113 - val_loss: 0.0079\n",
      "Epoch 135/200\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.0114 - val_loss: 0.0081\n",
      "Epoch 136/200\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.0114 - val_loss: 0.0080\n",
      "Epoch 137/200\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.0114 - val_loss: 0.0078\n",
      "Epoch 138/200\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.0113 - val_loss: 0.0081\n",
      "Epoch 139/200\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.0113 - val_loss: 0.0080\n",
      "Epoch 140/200\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.0113 - val_loss: 0.0079\n",
      "Epoch 141/200\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.0114 - val_loss: 0.0080\n",
      "Epoch 142/200\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.0114 - val_loss: 0.0080\n",
      "Epoch 143/200\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.0112 - val_loss: 0.0078\n",
      "Epoch 144/200\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.0114 - val_loss: 0.0078\n",
      "Epoch 145/200\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.0114 - val_loss: 0.0082\n",
      "Epoch 146/200\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.0112 - val_loss: 0.0080\n",
      "Epoch 147/200\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.0113 - val_loss: 0.0079\n",
      "Epoch 148/200\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.0113 - val_loss: 0.0079\n",
      "Epoch 149/200\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.0112 - val_loss: 0.0082\n",
      "Epoch 150/200\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.0112 - val_loss: 0.0081\n",
      "Epoch 151/200\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.0115 - val_loss: 0.0078\n",
      "Epoch 152/200\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.0114 - val_loss: 0.0080\n",
      "Epoch 153/200\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.0113 - val_loss: 0.0081\n",
      "Epoch 154/200\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.0114 - val_loss: 0.0080\n",
      "Epoch 155/200\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.0112 - val_loss: 0.0078\n",
      "Epoch 156/200\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.0114 - val_loss: 0.0078\n",
      "Epoch 157/200\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.0112 - val_loss: 0.0082\n",
      "Epoch 158/200\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.0114 - val_loss: 0.0079\n",
      "Epoch 159/200\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.0113 - val_loss: 0.0077\n",
      "Epoch 160/200\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.0113 - val_loss: 0.0079\n",
      "Epoch 161/200\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.0112 - val_loss: 0.0082\n",
      "Epoch 162/200\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.0114 - val_loss: 0.0080\n",
      "Epoch 163/200\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.0114 - val_loss: 0.0078\n",
      "Epoch 164/200\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.0114 - val_loss: 0.0079\n",
      "Epoch 165/200\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.0112 - val_loss: 0.0079\n",
      "Epoch 166/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 66ms/step - loss: 0.0114 - val_loss: 0.0081\n",
      "Epoch 167/200\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.0112 - val_loss: 0.0079\n",
      "Epoch 168/200\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.0115 - val_loss: 0.0080\n",
      "Epoch 169/200\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.0112 - val_loss: 0.0082\n",
      "Epoch 170/200\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.0113 - val_loss: 0.0079\n",
      "Epoch 171/200\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.0115 - val_loss: 0.0078\n",
      "Epoch 172/200\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.0112 - val_loss: 0.0081\n",
      "Epoch 173/200\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.0111 - val_loss: 0.0082\n",
      "Epoch 174/200\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.0112 - val_loss: 0.0078\n",
      "Epoch 175/200\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.0112 - val_loss: 0.0078\n",
      "Epoch 176/200\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.0112 - val_loss: 0.0079\n",
      "Epoch 177/200\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.0114 - val_loss: 0.0081\n",
      "Epoch 178/200\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.0111 - val_loss: 0.0079\n",
      "Epoch 179/200\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.0113 - val_loss: 0.0077\n",
      "Epoch 180/200\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.0111 - val_loss: 0.0079\n",
      "Epoch 181/200\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.0115 - val_loss: 0.0082\n",
      "Epoch 182/200\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.0112 - val_loss: 0.0079\n",
      "Epoch 183/200\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.0112 - val_loss: 0.0077\n",
      "Epoch 184/200\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 0.0114 - val_loss: 0.0080\n",
      "Epoch 185/200\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.0112 - val_loss: 0.0082\n",
      "Epoch 186/200\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.0113 - val_loss: 0.0079\n",
      "Epoch 187/200\n",
      "3/3 [==============================] - 0s 66ms/step - loss: 0.0112 - val_loss: 0.0077\n",
      "Epoch 188/200\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.0114 - val_loss: 0.0079\n",
      "Epoch 189/200\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.0113 - val_loss: 0.0082\n",
      "Epoch 190/200\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.0116 - val_loss: 0.0080\n",
      "Epoch 191/200\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.0113 - val_loss: 0.0079\n",
      "Epoch 192/200\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.0113 - val_loss: 0.0079\n",
      "Epoch 193/200\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.0113 - val_loss: 0.0079\n",
      "Epoch 194/200\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.0112 - val_loss: 0.0081\n",
      "Epoch 195/200\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.0114 - val_loss: 0.0080\n",
      "Epoch 196/200\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.0113 - val_loss: 0.0078\n",
      "Epoch 197/200\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.0111 - val_loss: 0.0079\n",
      "Epoch 198/200\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.0114 - val_loss: 0.0080\n",
      "Epoch 199/200\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.0114 - val_loss: 0.0079\n",
      "Epoch 200/200\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.0112 - val_loss: 0.0079\n"
     ]
    }
   ],
   "source": [
    "convlstm_model.compile(optimizer='adam', loss ='mse')\n",
    "history = convlstm_model.fit(X_train , Y_train, epochs=200, batch_size=256, verbose= 1,validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "5fb1e734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 11ms/step\n",
      "14/14 [==============================] - 0s 10ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_train = convlstm_model.predict(X_train)\n",
    "y_pred_test  = convlstm_model.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "99a86e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0101\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.010141022503376007"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convlstm_model.evaluate(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ae70b01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_squared_log_error, mean_absolute_percentage_error\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):    \n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "847a0477",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE value for LSTM Model  : 0.101 \n",
      "Train MSE value for LSTM Model  : 0.010 \n",
      "Train R2 value for LSTM Model  : 0.498 \n",
      "Train MAPE value for LSTM Model  : 146783796208.287 \n",
      "Train RMLSE value for LSTM Model  : 0.006 \n",
      "Train MAE value for LSTM Model  : 0.076 \n",
      "---------------------------------------------\n",
      "Test RMSE value for LSTM Model  : 0.079 \n",
      "Test MSE value for LSTM Model  : 0.006 \n",
      "Test R2 value for LSTM Model  : 0.429 \n",
      "Test MAPE value for LSTM Model  : 0.257 \n",
      "Test RMLSE value for LSTM Model  : 0.004 \n",
      "Test MAE value for LSTM Model  : 0.061 \n"
     ]
    }
   ],
   "source": [
    "print('Train RMSE value for LSTM Model  : %.3f ' % root_mean_squared_error(Y_train, y_pred_train))\n",
    "print('Train MSE value for LSTM Model  : %.3f ' % mean_squared_error(Y_train, y_pred_train))\n",
    "print('Train R2 value for LSTM Model  : %.3f ' % r2_score(Y_train, y_pred_train))\n",
    "print('Train MAPE value for LSTM Model  : %.3f ' % mean_absolute_percentage_error(Y_train, y_pred_train))\n",
    "print('Train RMLSE value for LSTM Model  : %.3f ' % mean_squared_log_error(Y_train, y_pred_train))\n",
    "print('Train MAE value for LSTM Model  : %.3f ' % mean_absolute_error(Y_train, y_pred_train))\n",
    "print('---------------------------------------------')\n",
    "print('Test RMSE value for LSTM Model  : %.3f ' % root_mean_squared_error(Y_test, y_pred_test))\n",
    "print('Test MSE value for LSTM Model  : %.3f ' % mean_squared_error(Y_test, y_pred_test))\n",
    "print('Test R2 value for LSTM Model  : %.3f ' % r2_score(Y_test, y_pred_test))\n",
    "print('Test MAPE value for LSTM Model  : %.3f ' % mean_absolute_percentage_error(Y_test, y_pred_test))\n",
    "print('Test RMLSE value for LSTM Model  : %.3f ' % mean_squared_log_error(Y_test, y_pred_test))\n",
    "print('Test MAE value for LSTM Model  : %.3f ' % mean_absolute_error(Y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "5b619a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "a9d76e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, scaler = scale_data(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "0c538f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_supervised(df):\n",
    "\n",
    "    input_features = []\n",
    "    ouput_feature = []\n",
    "    \n",
    "    len_df = df.shape[0]\n",
    "    \n",
    "    for i in range(len_df):\n",
    "        \n",
    "        end_idx = i + 7\n",
    "        \n",
    "        if end_idx > len_df-7:\n",
    "            break\n",
    "            \n",
    "        input_x , output_y = df[i:end_idx, 1:], df[end_idx: end_idx+7, 0]\n",
    "        \n",
    "        input_features.append(input_x)\n",
    "        ouput_feature.append(output_y)\n",
    "    \n",
    "    return np.array(input_features), np.array(ouput_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "86ea9d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of (training data) input features : (996, 7, 7) and ouput feature (996, 7)\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train = convert_to_supervised(X_train)\n",
    "print('Shape of (training data) input features : %s and ouput feature %s' % (X_train.shape, Y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "0860bf06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of (testing data) input features : (420, 7, 7) and ouput feature (420, 7)\n"
     ]
    }
   ],
   "source": [
    "X_test, Y_test = convert_to_supervised(X_test)\n",
    "print('Shape of (testing data) input features : %s and ouput feature %s' % (X_test.shape, Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "6ac1e77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps, n_features = X_train.shape[1], X_train.shape[2]\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10)\n",
    "convlstm_model = CL.ConvLstm(n_steps,n_features,7).getModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "27e09e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.reshape((X_train.shape[0],1,1,n_steps,X_train.shape[2]))\n",
    "X_test=X_test.reshape((X_test.shape[0],1,1,n_steps,X_test.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "99cdaf64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "3/3 [==============================] - 8s 577ms/step - loss: 0.2882 - val_loss: 0.2734\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 1s 206ms/step - loss: 0.2801 - val_loss: 0.2632\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 1s 241ms/step - loss: 0.2696 - val_loss: 0.2493\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 1s 228ms/step - loss: 0.2557 - val_loss: 0.2310\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 0.2370 - val_loss: 0.2069\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 1s 208ms/step - loss: 0.2129 - val_loss: 0.1770\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 1s 207ms/step - loss: 0.1834 - val_loss: 0.1474\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 1s 219ms/step - loss: 0.1576 - val_loss: 0.1290\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 1s 208ms/step - loss: 0.1413 - val_loss: 0.1236\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 1s 237ms/step - loss: 0.1340 - val_loss: 0.1142\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 1s 210ms/step - loss: 0.1233 - val_loss: 0.1011\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 1s 216ms/step - loss: 0.1141 - val_loss: 0.0961\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 1s 209ms/step - loss: 0.1130 - val_loss: 0.0979\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 1s 209ms/step - loss: 0.1151 - val_loss: 0.0992\n",
      "Epoch 15/200\n",
      "3/3 [==============================] - 1s 210ms/step - loss: 0.1158 - val_loss: 0.0989\n",
      "Epoch 16/200\n",
      "3/3 [==============================] - 1s 210ms/step - loss: 0.1149 - val_loss: 0.0980\n",
      "Epoch 17/200\n",
      "3/3 [==============================] - 1s 209ms/step - loss: 0.1138 - val_loss: 0.0970\n",
      "Epoch 18/200\n",
      "3/3 [==============================] - 1s 214ms/step - loss: 0.1126 - val_loss: 0.0961\n",
      "Epoch 19/200\n",
      "3/3 [==============================] - 1s 209ms/step - loss: 0.1117 - val_loss: 0.0953\n",
      "Epoch 20/200\n",
      "3/3 [==============================] - 1s 236ms/step - loss: 0.1110 - val_loss: 0.0946\n",
      "Epoch 21/200\n",
      "3/3 [==============================] - 1s 216ms/step - loss: 0.1104 - val_loss: 0.0941\n",
      "Epoch 22/200\n",
      "3/3 [==============================] - 1s 208ms/step - loss: 0.1097 - val_loss: 0.0934\n",
      "Epoch 23/200\n",
      "3/3 [==============================] - 1s 210ms/step - loss: 0.1089 - val_loss: 0.0923\n",
      "Epoch 24/200\n",
      "3/3 [==============================] - 1s 202ms/step - loss: 0.1078 - val_loss: 0.0906\n",
      "Epoch 25/200\n",
      "3/3 [==============================] - 1s 214ms/step - loss: 0.1062 - val_loss: 0.0887\n",
      "Epoch 26/200\n",
      "3/3 [==============================] - 1s 203ms/step - loss: 0.1043 - val_loss: 0.0866\n",
      "Epoch 27/200\n",
      "3/3 [==============================] - 1s 202ms/step - loss: 0.1020 - val_loss: 0.0836\n",
      "Epoch 28/200\n",
      "3/3 [==============================] - 1s 210ms/step - loss: 0.0994 - val_loss: 0.0804\n",
      "Epoch 29/200\n",
      "3/3 [==============================] - 1s 207ms/step - loss: 0.0965 - val_loss: 0.0762\n",
      "Epoch 30/200\n",
      "3/3 [==============================] - 1s 207ms/step - loss: 0.0933 - val_loss: 0.0718\n",
      "Epoch 31/200\n",
      "3/3 [==============================] - 1s 208ms/step - loss: 0.0909 - val_loss: 0.0696\n",
      "Epoch 32/200\n",
      "3/3 [==============================] - 1s 243ms/step - loss: 0.0882 - val_loss: 0.0682\n",
      "Epoch 33/200\n",
      "3/3 [==============================] - 1s 223ms/step - loss: 0.0877 - val_loss: 0.0700\n",
      "Epoch 34/200\n",
      "3/3 [==============================] - 1s 217ms/step - loss: 0.0876 - val_loss: 0.0707\n",
      "Epoch 35/200\n",
      "3/3 [==============================] - 1s 209ms/step - loss: 0.0874 - val_loss: 0.0699\n",
      "Epoch 36/200\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 0.0868 - val_loss: 0.0690\n",
      "Epoch 37/200\n",
      "3/3 [==============================] - 1s 214ms/step - loss: 0.0855 - val_loss: 0.0682\n",
      "Epoch 38/200\n",
      "3/3 [==============================] - 1s 208ms/step - loss: 0.0859 - val_loss: 0.0679\n",
      "Epoch 39/200\n",
      "3/3 [==============================] - 1s 214ms/step - loss: 0.0855 - val_loss: 0.0675\n",
      "Epoch 40/200\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 0.0847 - val_loss: 0.0682\n",
      "Epoch 41/200\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 0.0846 - val_loss: 0.0677\n",
      "Epoch 42/200\n",
      "3/3 [==============================] - 1s 225ms/step - loss: 0.0843 - val_loss: 0.0682\n",
      "Epoch 43/200\n",
      "3/3 [==============================] - 1s 211ms/step - loss: 0.0836 - val_loss: 0.0677\n",
      "Epoch 44/200\n",
      "3/3 [==============================] - 1s 220ms/step - loss: 0.0836 - val_loss: 0.0678\n",
      "Epoch 45/200\n",
      "3/3 [==============================] - 1s 210ms/step - loss: 0.0838 - val_loss: 0.0688\n",
      "Epoch 46/200\n",
      "3/3 [==============================] - 1s 220ms/step - loss: 0.0832 - val_loss: 0.0682\n",
      "Epoch 47/200\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 0.0829 - val_loss: 0.0681\n",
      "Epoch 48/200\n",
      "3/3 [==============================] - 1s 239ms/step - loss: 0.0832 - val_loss: 0.0677\n",
      "Epoch 49/200\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 0.0828 - val_loss: 0.0677\n",
      "Epoch 50/200\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 0.0827 - val_loss: 0.0675\n",
      "Epoch 51/200\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 0.0825 - val_loss: 0.0682\n",
      "Epoch 52/200\n",
      "3/3 [==============================] - 1s 216ms/step - loss: 0.0828 - val_loss: 0.0676\n",
      "Epoch 53/200\n",
      "3/3 [==============================] - 1s 239ms/step - loss: 0.0824 - val_loss: 0.0681\n",
      "Epoch 54/200\n",
      "3/3 [==============================] - 1s 222ms/step - loss: 0.0820 - val_loss: 0.0681\n",
      "Epoch 55/200\n",
      "3/3 [==============================] - 1s 211ms/step - loss: 0.0820 - val_loss: 0.0688\n",
      "Epoch 56/200\n",
      "3/3 [==============================] - 1s 210ms/step - loss: 0.0820 - val_loss: 0.0681\n",
      "Epoch 57/200\n",
      "3/3 [==============================] - 1s 224ms/step - loss: 0.0816 - val_loss: 0.0684\n",
      "Epoch 58/200\n",
      "3/3 [==============================] - 1s 214ms/step - loss: 0.0813 - val_loss: 0.0682\n",
      "Epoch 59/200\n",
      "3/3 [==============================] - 1s 207ms/step - loss: 0.0817 - val_loss: 0.0678\n",
      "Epoch 60/200\n",
      "3/3 [==============================] - 1s 230ms/step - loss: 0.0819 - val_loss: 0.0691\n",
      "Epoch 61/200\n",
      "3/3 [==============================] - 1s 237ms/step - loss: 0.0812 - val_loss: 0.0681\n",
      "Epoch 62/200\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 0.0813 - val_loss: 0.0687\n",
      "Epoch 63/200\n",
      "3/3 [==============================] - 1s 209ms/step - loss: 0.0810 - val_loss: 0.0679\n",
      "Epoch 64/200\n",
      "3/3 [==============================] - 1s 216ms/step - loss: 0.0811 - val_loss: 0.0691\n",
      "Epoch 65/200\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 0.0811 - val_loss: 0.0688\n",
      "Epoch 66/200\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 0.0809 - val_loss: 0.0686\n",
      "Epoch 67/200\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 0.0806 - val_loss: 0.0682\n",
      "Epoch 68/200\n",
      "3/3 [==============================] - 1s 209ms/step - loss: 0.0804 - val_loss: 0.0683\n",
      "Epoch 69/200\n",
      "3/3 [==============================] - 1s 211ms/step - loss: 0.0809 - val_loss: 0.0681\n",
      "Epoch 70/200\n",
      "3/3 [==============================] - 1s 207ms/step - loss: 0.0804 - val_loss: 0.0699\n",
      "Epoch 71/200\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 0.0806 - val_loss: 0.0690\n",
      "Epoch 72/200\n",
      "3/3 [==============================] - 1s 214ms/step - loss: 0.0808 - val_loss: 0.0681\n",
      "Epoch 73/200\n",
      "3/3 [==============================] - 1s 208ms/step - loss: 0.0807 - val_loss: 0.0689\n",
      "Epoch 74/200\n",
      "3/3 [==============================] - 1s 216ms/step - loss: 0.0810 - val_loss: 0.0682\n",
      "Epoch 75/200\n",
      "3/3 [==============================] - 1s 233ms/step - loss: 0.0805 - val_loss: 0.0710\n",
      "Epoch 76/200\n",
      "3/3 [==============================] - 1s 234ms/step - loss: 0.0807 - val_loss: 0.0688\n",
      "Epoch 77/200\n",
      "3/3 [==============================] - 1s 220ms/step - loss: 0.0802 - val_loss: 0.0684\n",
      "Epoch 78/200\n",
      "3/3 [==============================] - 1s 211ms/step - loss: 0.0800 - val_loss: 0.0687\n",
      "Epoch 79/200\n",
      "3/3 [==============================] - 1s 211ms/step - loss: 0.0799 - val_loss: 0.0684\n",
      "Epoch 80/200\n",
      "3/3 [==============================] - 1s 218ms/step - loss: 0.0796 - val_loss: 0.0690\n",
      "Epoch 81/200\n",
      "3/3 [==============================] - 1s 221ms/step - loss: 0.0799 - val_loss: 0.0690\n",
      "Epoch 82/200\n",
      "3/3 [==============================] - 1s 226ms/step - loss: 0.0800 - val_loss: 0.0684\n",
      "Epoch 83/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 225ms/step - loss: 0.0800 - val_loss: 0.0679\n",
      "Epoch 84/200\n",
      "3/3 [==============================] - 1s 232ms/step - loss: 0.0797 - val_loss: 0.0682\n",
      "Epoch 85/200\n",
      "3/3 [==============================] - 1s 214ms/step - loss: 0.0796 - val_loss: 0.0688\n",
      "Epoch 86/200\n",
      "3/3 [==============================] - 1s 225ms/step - loss: 0.0795 - val_loss: 0.0693\n",
      "Epoch 87/200\n",
      "3/3 [==============================] - 1s 211ms/step - loss: 0.0795 - val_loss: 0.0685\n",
      "Epoch 88/200\n",
      "3/3 [==============================] - 1s 226ms/step - loss: 0.0800 - val_loss: 0.0681\n",
      "Epoch 89/200\n",
      "3/3 [==============================] - 1s 223ms/step - loss: 0.0802 - val_loss: 0.0680\n",
      "Epoch 90/200\n",
      "3/3 [==============================] - 1s 210ms/step - loss: 0.0798 - val_loss: 0.0686\n",
      "Epoch 91/200\n",
      "3/3 [==============================] - 1s 216ms/step - loss: 0.0795 - val_loss: 0.0690\n",
      "Epoch 92/200\n",
      "3/3 [==============================] - 1s 211ms/step - loss: 0.0795 - val_loss: 0.0683\n",
      "Epoch 93/200\n",
      "3/3 [==============================] - 1s 238ms/step - loss: 0.0798 - val_loss: 0.0686\n",
      "Epoch 94/200\n",
      "3/3 [==============================] - 1s 248ms/step - loss: 0.0797 - val_loss: 0.0690\n",
      "Epoch 95/200\n",
      "3/3 [==============================] - 1s 208ms/step - loss: 0.0796 - val_loss: 0.0689\n",
      "Epoch 96/200\n",
      "3/3 [==============================] - 1s 209ms/step - loss: 0.0794 - val_loss: 0.0688\n",
      "Epoch 97/200\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 0.0794 - val_loss: 0.0682\n",
      "Epoch 98/200\n",
      "3/3 [==============================] - 1s 210ms/step - loss: 0.0796 - val_loss: 0.0685\n",
      "Epoch 99/200\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 0.0793 - val_loss: 0.0687\n",
      "Epoch 100/200\n",
      "3/3 [==============================] - 1s 211ms/step - loss: 0.0799 - val_loss: 0.0689\n",
      "Epoch 101/200\n",
      "3/3 [==============================] - 1s 210ms/step - loss: 0.0795 - val_loss: 0.0693\n",
      "Epoch 102/200\n",
      "3/3 [==============================] - 1s 209ms/step - loss: 0.0798 - val_loss: 0.0683\n",
      "Epoch 103/200\n",
      "3/3 [==============================] - 1s 218ms/step - loss: 0.0795 - val_loss: 0.0687\n",
      "Epoch 104/200\n",
      "3/3 [==============================] - 1s 219ms/step - loss: 0.0791 - val_loss: 0.0681\n",
      "Epoch 105/200\n",
      "3/3 [==============================] - 1s 224ms/step - loss: 0.0799 - val_loss: 0.0688\n",
      "Epoch 106/200\n",
      "3/3 [==============================] - 1s 246ms/step - loss: 0.0794 - val_loss: 0.0691\n",
      "Epoch 107/200\n",
      "3/3 [==============================] - 1s 228ms/step - loss: 0.0792 - val_loss: 0.0690\n",
      "Epoch 108/200\n",
      "3/3 [==============================] - 1s 246ms/step - loss: 0.0793 - val_loss: 0.0684\n",
      "Epoch 109/200\n",
      "3/3 [==============================] - 1s 225ms/step - loss: 0.0795 - val_loss: 0.0682\n",
      "Epoch 110/200\n",
      "3/3 [==============================] - 1s 218ms/step - loss: 0.0796 - val_loss: 0.0691\n",
      "Epoch 111/200\n",
      "3/3 [==============================] - 1s 218ms/step - loss: 0.0795 - val_loss: 0.0685\n",
      "Epoch 112/200\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 0.0795 - val_loss: 0.0686\n",
      "Epoch 113/200\n",
      "3/3 [==============================] - 1s 210ms/step - loss: 0.0792 - val_loss: 0.0684\n",
      "Epoch 114/200\n",
      "3/3 [==============================] - 1s 220ms/step - loss: 0.0793 - val_loss: 0.0693\n",
      "Epoch 115/200\n",
      "3/3 [==============================] - 1s 206ms/step - loss: 0.0795 - val_loss: 0.0687\n",
      "Epoch 116/200\n",
      "3/3 [==============================] - 1s 210ms/step - loss: 0.0791 - val_loss: 0.0683\n",
      "Epoch 117/200\n",
      "3/3 [==============================] - 1s 208ms/step - loss: 0.0790 - val_loss: 0.0682\n",
      "Epoch 118/200\n",
      "3/3 [==============================] - 1s 206ms/step - loss: 0.0792 - val_loss: 0.0687\n",
      "Epoch 119/200\n",
      "3/3 [==============================] - 1s 206ms/step - loss: 0.0790 - val_loss: 0.0687\n",
      "Epoch 120/200\n",
      "3/3 [==============================] - 1s 204ms/step - loss: 0.0792 - val_loss: 0.0681\n",
      "Epoch 121/200\n",
      "3/3 [==============================] - 1s 208ms/step - loss: 0.0792 - val_loss: 0.0684\n",
      "Epoch 122/200\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 0.0788 - val_loss: 0.0684\n",
      "Epoch 123/200\n",
      "3/3 [==============================] - 1s 206ms/step - loss: 0.0791 - val_loss: 0.0689\n",
      "Epoch 124/200\n",
      "3/3 [==============================] - 1s 204ms/step - loss: 0.0791 - val_loss: 0.0687\n",
      "Epoch 125/200\n",
      "3/3 [==============================] - 1s 211ms/step - loss: 0.0790 - val_loss: 0.0684\n",
      "Epoch 126/200\n",
      "3/3 [==============================] - 1s 248ms/step - loss: 0.0790 - val_loss: 0.0690\n",
      "Epoch 127/200\n",
      "3/3 [==============================] - 1s 229ms/step - loss: 0.0792 - val_loss: 0.0686\n",
      "Epoch 128/200\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 0.0792 - val_loss: 0.0688\n",
      "Epoch 129/200\n",
      "3/3 [==============================] - 1s 243ms/step - loss: 0.0790 - val_loss: 0.0685\n",
      "Epoch 130/200\n",
      "3/3 [==============================] - 1s 226ms/step - loss: 0.0788 - val_loss: 0.0686\n",
      "Epoch 131/200\n",
      "3/3 [==============================] - 1s 209ms/step - loss: 0.0788 - val_loss: 0.0691\n",
      "Epoch 132/200\n",
      "3/3 [==============================] - 1s 214ms/step - loss: 0.0789 - val_loss: 0.0686\n",
      "Epoch 133/200\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 0.0789 - val_loss: 0.0685\n",
      "Epoch 134/200\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 0.0792 - val_loss: 0.0690\n",
      "Epoch 135/200\n",
      "3/3 [==============================] - 1s 248ms/step - loss: 0.0791 - val_loss: 0.0685\n",
      "Epoch 136/200\n",
      "3/3 [==============================] - 1s 229ms/step - loss: 0.0785 - val_loss: 0.0695\n",
      "Epoch 137/200\n",
      "3/3 [==============================] - 1s 214ms/step - loss: 0.0790 - val_loss: 0.0682\n",
      "Epoch 138/200\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 0.0789 - val_loss: 0.0687\n",
      "Epoch 139/200\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 0.0789 - val_loss: 0.0685\n",
      "Epoch 140/200\n",
      "3/3 [==============================] - 1s 220ms/step - loss: 0.0786 - val_loss: 0.0684\n",
      "Epoch 141/200\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 0.0791 - val_loss: 0.0685\n",
      "Epoch 142/200\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 0.0790 - val_loss: 0.0686\n",
      "Epoch 143/200\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 0.0788 - val_loss: 0.0680\n",
      "Epoch 144/200\n",
      "3/3 [==============================] - 1s 216ms/step - loss: 0.0787 - val_loss: 0.0687\n",
      "Epoch 145/200\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 0.0784 - val_loss: 0.0691\n",
      "Epoch 146/200\n",
      "3/3 [==============================] - 1s 223ms/step - loss: 0.0784 - val_loss: 0.0684\n",
      "Epoch 147/200\n",
      "3/3 [==============================] - 1s 219ms/step - loss: 0.0784 - val_loss: 0.0685\n",
      "Epoch 148/200\n",
      "3/3 [==============================] - 1s 219ms/step - loss: 0.0784 - val_loss: 0.0690\n",
      "Epoch 149/200\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 0.0784 - val_loss: 0.0685\n",
      "Epoch 150/200\n",
      "3/3 [==============================] - 1s 229ms/step - loss: 0.0789 - val_loss: 0.0683\n",
      "Epoch 151/200\n",
      "3/3 [==============================] - 1s 219ms/step - loss: 0.0784 - val_loss: 0.0682\n",
      "Epoch 152/200\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 0.0784 - val_loss: 0.0687\n",
      "Epoch 153/200\n",
      "3/3 [==============================] - 1s 217ms/step - loss: 0.0782 - val_loss: 0.0686\n",
      "Epoch 154/200\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 0.0784 - val_loss: 0.0685\n",
      "Epoch 155/200\n",
      "3/3 [==============================] - 1s 210ms/step - loss: 0.0784 - val_loss: 0.0691\n",
      "Epoch 156/200\n",
      "3/3 [==============================] - 1s 214ms/step - loss: 0.0785 - val_loss: 0.0678\n",
      "Epoch 157/200\n",
      "3/3 [==============================] - 1s 214ms/step - loss: 0.0787 - val_loss: 0.0683\n",
      "Epoch 158/200\n",
      "3/3 [==============================] - 1s 230ms/step - loss: 0.0785 - val_loss: 0.0688\n",
      "Epoch 159/200\n",
      "3/3 [==============================] - 1s 218ms/step - loss: 0.0783 - val_loss: 0.0685\n",
      "Epoch 160/200\n",
      "3/3 [==============================] - 1s 220ms/step - loss: 0.0782 - val_loss: 0.0688\n",
      "Epoch 161/200\n",
      "3/3 [==============================] - 1s 220ms/step - loss: 0.0783 - val_loss: 0.0684\n",
      "Epoch 162/200\n",
      "3/3 [==============================] - 1s 217ms/step - loss: 0.0786 - val_loss: 0.0682\n",
      "Epoch 163/200\n",
      "3/3 [==============================] - 1s 237ms/step - loss: 0.0778 - val_loss: 0.0686\n",
      "Epoch 164/200\n",
      "3/3 [==============================] - 1s 225ms/step - loss: 0.0783 - val_loss: 0.0681\n",
      "Epoch 165/200\n",
      "3/3 [==============================] - 1s 228ms/step - loss: 0.0780 - val_loss: 0.0687\n",
      "Epoch 166/200\n",
      "3/3 [==============================] - 1s 219ms/step - loss: 0.0782 - val_loss: 0.0682\n",
      "Epoch 167/200\n",
      "3/3 [==============================] - 1s 221ms/step - loss: 0.0781 - val_loss: 0.0679\n",
      "Epoch 168/200\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 0.0785 - val_loss: 0.0688\n",
      "Epoch 169/200\n",
      "3/3 [==============================] - 1s 209ms/step - loss: 0.0782 - val_loss: 0.0688\n",
      "Epoch 170/200\n",
      "3/3 [==============================] - 1s 220ms/step - loss: 0.0779 - val_loss: 0.0679\n",
      "Epoch 171/200\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 0.0783 - val_loss: 0.0682\n",
      "Epoch 172/200\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 0.0780 - val_loss: 0.0689\n",
      "Epoch 173/200\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 0.0781 - val_loss: 0.0680\n",
      "Epoch 174/200\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 0.0783 - val_loss: 0.0684\n",
      "Epoch 175/200\n",
      "3/3 [==============================] - 1s 219ms/step - loss: 0.0784 - val_loss: 0.0687\n",
      "Epoch 176/200\n",
      "3/3 [==============================] - 1s 228ms/step - loss: 0.0781 - val_loss: 0.0687\n",
      "Epoch 177/200\n",
      "3/3 [==============================] - 1s 221ms/step - loss: 0.0781 - val_loss: 0.0685\n",
      "Epoch 178/200\n",
      "3/3 [==============================] - 1s 218ms/step - loss: 0.0785 - val_loss: 0.0682\n",
      "Epoch 179/200\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 0.0780 - val_loss: 0.0690\n",
      "Epoch 180/200\n",
      "3/3 [==============================] - 1s 216ms/step - loss: 0.0777 - val_loss: 0.0681\n",
      "Epoch 181/200\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 0.0782 - val_loss: 0.0691\n",
      "Epoch 182/200\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 0.0786 - val_loss: 0.0681\n",
      "Epoch 183/200\n",
      "3/3 [==============================] - 1s 208ms/step - loss: 0.0783 - val_loss: 0.0681\n",
      "Epoch 184/200\n",
      "3/3 [==============================] - 1s 207ms/step - loss: 0.0784 - val_loss: 0.0690\n",
      "Epoch 185/200\n",
      "3/3 [==============================] - 1s 206ms/step - loss: 0.0782 - val_loss: 0.0678\n",
      "Epoch 186/200\n",
      "3/3 [==============================] - 1s 206ms/step - loss: 0.0783 - val_loss: 0.0686\n",
      "Epoch 187/200\n",
      "3/3 [==============================] - 1s 208ms/step - loss: 0.0778 - val_loss: 0.0679\n",
      "Epoch 188/200\n",
      "3/3 [==============================] - 1s 209ms/step - loss: 0.0780 - val_loss: 0.0691\n",
      "Epoch 189/200\n",
      "3/3 [==============================] - 1s 208ms/step - loss: 0.0779 - val_loss: 0.0686\n",
      "Epoch 190/200\n",
      "3/3 [==============================] - 1s 202ms/step - loss: 0.0777 - val_loss: 0.0685\n",
      "Epoch 191/200\n",
      "3/3 [==============================] - 1s 214ms/step - loss: 0.0779 - val_loss: 0.0680\n",
      "Epoch 192/200\n",
      "3/3 [==============================] - 1s 209ms/step - loss: 0.0776 - val_loss: 0.0684\n",
      "Epoch 193/200\n",
      "3/3 [==============================] - 1s 251ms/step - loss: 0.0777 - val_loss: 0.0691\n",
      "Epoch 194/200\n",
      "3/3 [==============================] - 1s 228ms/step - loss: 0.0780 - val_loss: 0.0688\n",
      "Epoch 195/200\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 0.0779 - val_loss: 0.0685\n",
      "Epoch 196/200\n",
      "3/3 [==============================] - 1s 216ms/step - loss: 0.0781 - val_loss: 0.0687\n",
      "Epoch 197/200\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 0.0778 - val_loss: 0.0680\n",
      "Epoch 198/200\n",
      "3/3 [==============================] - 1s 214ms/step - loss: 0.0774 - val_loss: 0.0690\n",
      "Epoch 199/200\n",
      "3/3 [==============================] - 1s 211ms/step - loss: 0.0776 - val_loss: 0.0686\n",
      "Epoch 200/200\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 0.0777 - val_loss: 0.0689\n"
     ]
    }
   ],
   "source": [
    "convlstm_model.compile(optimizer='adam', loss ='mae')\n",
    "history = convlstm_model.fit(X_train , Y_train, epochs=200, batch_size=256, verbose= 1,validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "ed95614b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 15ms/step\n",
      "14/14 [==============================] - 0s 14ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_train = convlstm_model.predict(X_train)\n",
    "y_pred_test  = convlstm_model.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "53940bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE value for LSTM Model  : 0.103 \n",
      "Train MSE value for LSTM Model  : 0.011 \n",
      "Train R2 value for LSTM Model  : 0.455 \n",
      "Train MAPE value for LSTM Model  : 29462041405.988 \n",
      "Train MAE value for LSTM Model  : 0.074 \n",
      "---------------------------------------------\n",
      "Test RMSE value for LSTM Model  : 0.081 \n",
      "Test MSE value for LSTM Model  : 0.007 \n",
      "Test R2 value for LSTM Model  : 0.408 \n",
      "Test MAPE value for LSTM Model  : 0.264 \n",
      "Test MAE value for LSTM Model  : 0.062 \n"
     ]
    }
   ],
   "source": [
    "print('Train RMSE value for LSTM Model  : %.3f ' % root_mean_squared_error(Y_train, y_pred_train))\n",
    "print('Train MSE value for LSTM Model  : %.3f ' % mean_squared_error(Y_train, y_pred_train))\n",
    "print('Train R2 value for LSTM Model  : %.3f ' % r2_score(Y_train, y_pred_train))\n",
    "print('Train MAPE value for LSTM Model  : %.3f ' % mean_absolute_percentage_error(Y_train, y_pred_train))\n",
    "#print('Train RMLSE value for LSTM Model  : %.3f ' % mean_squared_log_error(Y_train, y_pred_train))\n",
    "print('Train MAE value for LSTM Model  : %.3f ' % mean_absolute_error(Y_train, y_pred_train))\n",
    "print('---------------------------------------------')\n",
    "print('Test RMSE value for LSTM Model  : %.3f ' % root_mean_squared_error(Y_test, y_pred_test))\n",
    "print('Test MSE value for LSTM Model  : %.3f ' % mean_squared_error(Y_test, y_pred_test))\n",
    "print('Test R2 value for LSTM Model  : %.3f ' % r2_score(Y_test, y_pred_test))\n",
    "print('Test MAPE value for LSTM Model  : %.3f ' % mean_absolute_percentage_error(Y_test, y_pred_test))\n",
    "#print('Test RMLSE value for LSTM Model  : %.3f ' % mean_squared_log_error(Y_test, y_pred_test))\n",
    "print('Test MAE value for LSTM Model  : %.3f ' % mean_absolute_error(Y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "74bf038e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 15ms/step - loss: 0.0744\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.07443315535783768"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convlstm_model.evaluate(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "29726dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 18ms/step - loss: 0.0623\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.062288351356983185"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convlstm_model.evaluate(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36553c0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
